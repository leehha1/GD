{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GD diploma project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8lzHv-A_S4qh",
        "ChGzMdC6S6sK",
        "PfXwENhIS7HR",
        "frAFbG0VS7-_",
        "e9RmZDb8S8Sk",
        "d-eWXTCsTPA_",
        "nI5Sfn_oTTCF",
        "1kcPTxdt-x_9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Kr4q1SpJHXU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9feed182-29e0-48ec-9272-4a6a6ddfc560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "-sjJo3dcQNuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b63823a5-c97c-4630-c207-313c7fb2b2d2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.3.0)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession, Window\n",
        "import pyspark.sql.types as t\n",
        "import pyspark.sql.functions as f\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "import unittest\n",
        "import pytest"
      ],
      "metadata": {
        "id": "HbeydiRcQPWd"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_session = (SparkSession.builder\n",
        "                             .master(\"local\") \n",
        "                             .appName(\"diploma project app\")\n",
        "                             .config(conf=SparkConf()) \n",
        "                             .getOrCreate())"
      ],
      "metadata": {
        "id": "MwBIHfm7QRMu"
      },
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print((filtered_title_basics_df.count(), len(filtered_title_basics_df.columns)))"
      ],
      "metadata": {
        "id": "hNtHXaN_65Ed"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv(path, work_schema, spark_session):\n",
        "  \"\"\"Read data from CSV\"\"\"\n",
        "  work_df = spark_session.read.csv(path,\n",
        "                                   sep=r'\\t',\n",
        "                                   header=True,\n",
        "                                   nullValue=r'\\N',\n",
        "                                   schema=work_schema)\n",
        "  return work_df"
      ],
      "metadata": {
        "id": "uK571c0uU2jZ"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_csv(df, path_to_save):\n",
        "  \"\"\"Write dafaframe to CSV as 1 file\"\"\"\n",
        "  df.coalesce(1).write.csv(path_to_save, header=True, mode=\"overwrite\")"
      ],
      "metadata": {
        "id": "PEiEM_J912G6"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read all df"
      ],
      "metadata": {
        "id": "EQnEXzWWVIXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read title.akas"
      ],
      "metadata": {
        "id": "iiIMYEaVVWv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_title_akas = '/content/drive/MyDrive/GD/input_files/title.akas/data.tsv'\n",
        "schema_title_akas = t.StructType([t.StructField('TitleId', t.StringType(), True),\n",
        "                                t.StructField('Ordering', t.IntegerType(), True),\n",
        "                                t.StructField('Title', t.StringType(), True),\n",
        "                                t.StructField('Region', t.StringType(), True),\n",
        "                                t.StructField('Language', t.StringType(), True),\n",
        "                                t.StructField('Types', t.StringType(), True),\n",
        "                                t.StructField('Attributes', t.StringType(), True),\n",
        "                                t.StructField('IsOriginalTitle ',t.IntegerType(),True),\n",
        "])\n",
        "title_akas_df = read_csv(path_title_akas, schema_title_akas, spark_session)\n",
        "title_akas_df.show(40, truncate=False)"
      ],
      "metadata": {
        "id": "lNWj9hAlVNbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fc5ba20d-a19e-43ef-f04b-1dc12ec033f9"
      },
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-------------------------+------+--------+-----------+--------------------------+----------------+\n",
            "|TitleId  |Ordering|Title                    |Region|Language|Types      |Attributes                |IsOriginalTitle |\n",
            "+---------+--------+-------------------------+------+--------+-----------+--------------------------+----------------+\n",
            "|tt0000001|1       |Карменсіта               |UA    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000001|2       |Carmencita               |DE    |null    |null       |literal title             |0               |\n",
            "|tt0000001|3       |Carmencita - spanyol tánc|HU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000001|4       |Καρμενσίτα               |GR    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000001|5       |Карменсита               |RU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000001|6       |Carmencita               |US    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000001|7       |Carmencita               |null  |null    |original   |null                      |1               |\n",
            "|tt0000001|8       |カルメンチータ           |JP    |ja      |imdbDisplay|null                      |0               |\n",
            "|tt0000002|1       |Le clown et ses chiens   |null  |null    |original   |null                      |1               |\n",
            "|tt0000002|2       |Le clown et ses chiens   |FR    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000002|3       |A bohóc és kutyái        |HU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000002|4       |Der Clown und seine Hunde|DE    |null    |null       |literal title             |0               |\n",
            "|tt0000002|5       |Clovnul si cainii sai    |RO    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000002|6       |Клоун и его собаки       |RU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000002|7       |The Clown and His Dogs   |US    |null    |null       |literal English title     |0               |\n",
            "|tt0000002|8       |道化師と犬               |JP    |ja      |imdbDisplay|null                      |0               |\n",
            "|tt0000003|1       |Sarmanul Pierrot         |RO    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000003|2       |Szegény Pierrot          |HU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000003|3       |哀れなピエロ             |JP    |ja      |imdbDisplay|null                      |0               |\n",
            "|tt0000003|4       |Бідний П'єро             |UA    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000003|5       |Бедный Пьеро             |RU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000003|6       |Pauvre Pierrot           |null  |null    |original   |null                      |1               |\n",
            "|tt0000003|7       |Poor Pierrot             |GB    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000003|8       |Pauvre Pierrot           |FR    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000003|9       |Armer Pierrot            |DE    |null    |null       |literal title             |0               |\n",
            "|tt0000004|1       |Un bon bock              |null  |null    |original   |null                      |1               |\n",
            "|tt0000004|2       |Un bon bock              |FR    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000004|3       |Ein gutes Glas Bier      |DE    |null    |null       |literal title             |0               |\n",
            "|tt0000004|4       |Un ţap de bere           |RO    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000004|5       |Полная кружка пива       |RU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000004|6       |一杯のビール             |JP    |ja      |imdbDisplay|null                      |0               |\n",
            "|tt0000004|7       |A Good Beer              |null  |null    |null       |null                      |0               |\n",
            "|tt0000004|8       |Egy jó pohár sör         |HU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000005|10      |Blacksmith Scene         |US    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000005|11      |Blacksmith Scene         |null  |null    |original   |null                      |1               |\n",
            "|tt0000005|12      |The Blacksmith's Forge   |GB    |null    |null       |informal alternative title|0               |\n",
            "|tt0000005|1       |Blacksmithing Scene      |US    |null    |alternative|null                      |0               |\n",
            "|tt0000005|2       |Ковальська сцена         |UA    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000005|3       |Сцена в кузне            |RU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000005|4       |Blacksmith Scene         |CA    |en      |imdbDisplay|null                      |0               |\n",
            "+---------+--------+-------------------------+------+--------+-----------+--------------------------+----------------+\n",
            "only showing top 40 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read name.basics"
      ],
      "metadata": {
        "id": "YNBHyQFrWdpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_name_basics = '/content/drive/MyDrive/GD/input_files/name.basics/data.tsv'\n",
        "schema_name_basics = t.StructType([t.StructField('TitleId', t.StringType(), True),\n",
        "                                  t.StructField('PrimaryName', t.StringType(), True),\n",
        "                                  t.StructField('BirthYear', t.IntegerType(), True),\n",
        "                                  t.StructField('DeathYear', t.IntegerType(), True),\n",
        "                                  t.StructField('PrimaryProfession', t.StringType(), True),\n",
        "                                  t.StructField('KnownForTitles', t.StringType(), True),\n",
        "])\n",
        "\n",
        "name_basics_df = read_csv(path_name_basics, schema_name_basics, spark_session)\n",
        "name_basics_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "qumE6PD-VNe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de00282-9808-4d00-94d6-feda27a28bca"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+---------+---------+-------------------------------------+---------------------------------------+\n",
            "|TitleId  |PrimaryName        |BirthYear|DeathYear|PrimaryProfession                    |KnownForTitles                         |\n",
            "+---------+-------------------+---------+---------+-------------------------------------+---------------------------------------+\n",
            "|nm0000001|Fred Astaire       |1899     |1987     |soundtrack,actor,miscellaneous       |tt0072308,tt0053137,tt0050419,tt0031983|\n",
            "|nm0000002|Lauren Bacall      |1924     |2014     |actress,soundtrack                   |tt0038355,tt0117057,tt0071877,tt0037382|\n",
            "|nm0000003|Brigitte Bardot    |1934     |null     |actress,soundtrack,music_department  |tt0057345,tt0049189,tt0054452,tt0056404|\n",
            "|nm0000004|John Belushi       |1949     |1982     |actor,soundtrack,writer              |tt0078723,tt0077975,tt0072562,tt0080455|\n",
            "|nm0000005|Ingmar Bergman     |1918     |2007     |writer,director,actor                |tt0083922,tt0050986,tt0060827,tt0050976|\n",
            "|nm0000006|Ingrid Bergman     |1915     |1982     |actress,soundtrack,producer          |tt0034583,tt0077711,tt0036855,tt0038109|\n",
            "|nm0000007|Humphrey Bogart    |1899     |1957     |actor,soundtrack,producer            |tt0043265,tt0037382,tt0034583,tt0042593|\n",
            "|nm0000008|Marlon Brando      |1924     |2004     |actor,soundtrack,director            |tt0068646,tt0078788,tt0070849,tt0047296|\n",
            "|nm0000009|Richard Burton     |1925     |1984     |actor,soundtrack,producer            |tt0059749,tt0087803,tt0061184,tt0057877|\n",
            "|nm0000010|James Cagney       |1899     |1986     |actor,soundtrack,director            |tt0042041,tt0035575,tt0055256,tt0029870|\n",
            "|nm0000011|Gary Cooper        |1901     |1961     |actor,soundtrack,producer            |tt0044706,tt0034167,tt0035896,tt0027996|\n",
            "|nm0000012|Bette Davis        |1908     |1989     |actress,soundtrack,make_up_department|tt0031210,tt0035140,tt0056687,tt0042192|\n",
            "|nm0000013|Doris Day          |1922     |2019     |soundtrack,actress,producer          |tt0049470,tt0053172,tt0048317,tt0045591|\n",
            "|nm0000014|Olivia de Havilland|1916     |2020     |actress,soundtrack                   |tt0031381,tt0041452,tt0040806,tt0029843|\n",
            "|nm0000015|James Dean         |1931     |1955     |actor,miscellaneous                  |tt0048028,tt0039123,tt0049261,tt0048545|\n",
            "|nm0000016|Georges Delerue    |1925     |1992     |composer,soundtrack,music_department |tt0096320,tt0069946,tt8847712,tt0091763|\n",
            "|nm0000017|Marlene Dietrich   |1901     |1992     |soundtrack,actress,music_department  |tt0052311,tt0055031,tt0051201,tt0021156|\n",
            "|nm0000018|Kirk Douglas       |1916     |2020     |actor,producer,soundtrack            |tt0080736,tt0043338,tt0054331,tt0049456|\n",
            "|nm0000019|Federico Fellini   |1920     |1993     |writer,director,assistant_director   |tt0071129,tt0053779,tt0050783,tt0056801|\n",
            "|nm0000020|Henry Fonda        |1905     |1982     |actor,producer,soundtrack            |tt0051207,tt0032551,tt0050083,tt0082846|\n",
            "+---------+-------------------+---------+---------+-------------------------------------+---------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read title.basics"
      ],
      "metadata": {
        "id": "pyyalQq9WjWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_title_basics = '/content/drive/MyDrive/GD/input_files/title.basics/data.tsv'\n",
        "  \n",
        "schema_title_basics = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                            t.StructField('TitleType', t.StringType(), True),\n",
        "                            t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                            t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                            t.StructField('IsAdult', t.IntegerType(), True),\n",
        "                            t.StructField('StartYear', t.IntegerType(), True),\n",
        "                            t.StructField('EndYear', t.IntegerType(), True),\n",
        "                            t.StructField('RuntimeMinutes', t.IntegerType(), True),\n",
        "                            t.StructField('Genres', t.StringType(), True),\n",
        "])\n",
        "\n",
        "title_basics_df = read_csv(path_title_basics, schema_title_basics, spark_session)\n",
        "title_basics_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "mpHy-sJgVNkp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5afbf36-65f2-46c9-c1e9-6f25c46052ae"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+-------------------------------------------+-------------------------------------------------+-------+---------+-------+--------------+------------------------+\n",
            "|Tconst   |TitleType|PrimaryTitle                               |OriginalTitle                                    |IsAdult|StartYear|EndYear|RuntimeMinutes|Genres                  |\n",
            "+---------+---------+-------------------------------------------+-------------------------------------------------+-------+---------+-------+--------------+------------------------+\n",
            "|tt0000001|short    |Carmencita                                 |Carmencita                                       |0      |1894     |null   |1             |Documentary,Short       |\n",
            "|tt0000002|short    |Le clown et ses chiens                     |Le clown et ses chiens                           |0      |1892     |null   |5             |Animation,Short         |\n",
            "|tt0000003|short    |Pauvre Pierrot                             |Pauvre Pierrot                                   |0      |1892     |null   |4             |Animation,Comedy,Romance|\n",
            "|tt0000004|short    |Un bon bock                                |Un bon bock                                      |0      |1892     |null   |12            |Animation,Short         |\n",
            "|tt0000005|short    |Blacksmith Scene                           |Blacksmith Scene                                 |0      |1893     |null   |1             |Comedy,Short            |\n",
            "|tt0000006|short    |Chinese Opium Den                          |Chinese Opium Den                                |0      |1894     |null   |1             |Short                   |\n",
            "|tt0000007|short    |Corbett and Courtney Before the Kinetograph|Corbett and Courtney Before the Kinetograph      |0      |1894     |null   |1             |Short,Sport             |\n",
            "|tt0000008|short    |Edison Kinetoscopic Record of a Sneeze     |Edison Kinetoscopic Record of a Sneeze           |0      |1894     |null   |1             |Documentary,Short       |\n",
            "|tt0000009|movie    |Miss Jerry                                 |Miss Jerry                                       |0      |1894     |null   |45            |Romance                 |\n",
            "|tt0000010|short    |Leaving the Factory                        |La sortie de l'usine Lumière à Lyon              |0      |1895     |null   |1             |Documentary,Short       |\n",
            "|tt0000011|short    |Akrobatisches Potpourri                    |Akrobatisches Potpourri                          |0      |1895     |null   |1             |Documentary,Short       |\n",
            "|tt0000012|short    |The Arrival of a Train                     |L'arrivée d'un train à La Ciotat                 |0      |1896     |null   |1             |Documentary,Short       |\n",
            "|tt0000013|short    |The Photographical Congress Arrives in Lyon|Le débarquement du congrès de photographie à Lyon|0      |1895     |null   |1             |Documentary,Short       |\n",
            "|tt0000014|short    |The Waterer Watered                        |L'arroseur arrosé                                |0      |1895     |null   |1             |Comedy,Short            |\n",
            "|tt0000015|short    |Autour d'une cabine                        |Autour d'une cabine                              |0      |1894     |null   |2             |Animation,Short         |\n",
            "|tt0000016|short    |Boat Leaving the Port                      |Barque sortant du port                           |0      |1895     |null   |1             |Documentary,Short       |\n",
            "|tt0000017|short    |Italienischer Bauerntanz                   |Italienischer Bauerntanz                         |0      |1895     |null   |1             |Documentary,Short       |\n",
            "|tt0000018|short    |Das boxende Känguruh                       |Das boxende Känguruh                             |0      |1895     |null   |1             |Short                   |\n",
            "|tt0000019|short    |The Clown Barber                           |The Clown Barber                                 |0      |1898     |null   |null          |Comedy,Short            |\n",
            "|tt0000020|short    |The Derby 1895                             |The Derby 1895                                   |0      |1895     |null   |1             |Documentary,Short,Sport |\n",
            "+---------+---------+-------------------------------------------+-------------------------------------------------+-------+---------+-------+--------------+------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read title.principals"
      ],
      "metadata": {
        "id": "tmrEPGAcXRNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_title_principals = '/content/drive/MyDrive/GD/input_files/title.principals/data.tsv'\n",
        "  \n",
        "schema_title_principals = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                        t.StructField('Ordering', t.IntegerType(), True),\n",
        "                                        t.StructField('Nconst', t.StringType(), True),\n",
        "                                        t.StructField('Category', t.StringType(), True),\n",
        "                                        t.StructField('Job', t.StringType(), True),\n",
        "                                        t.StructField('Characters', t.StringType(), True),\n",
        "                                      ])\n",
        "\n",
        "title_principals_df = read_csv(path_title_principals, schema_title_principals, spark_session)\n",
        "title_principals_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "U-GdaRh2VNnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957789d2-a771-4897-a0c9-288e232b58e2"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+---------+---------------+-----------------------+--------------+\n",
            "|Tconst   |Ordering|Nconst   |Category       |Job                    |Characters    |\n",
            "+---------+--------+---------+---------------+-----------------------+--------------+\n",
            "|tt0000001|1       |nm1588970|self           |null                   |[\"Self\"]      |\n",
            "|tt0000001|2       |nm0005690|director       |null                   |null          |\n",
            "|tt0000001|3       |nm0374658|cinematographer|director of photography|null          |\n",
            "|tt0000002|1       |nm0721526|director       |null                   |null          |\n",
            "|tt0000002|2       |nm1335271|composer       |null                   |null          |\n",
            "|tt0000003|1       |nm0721526|director       |null                   |null          |\n",
            "|tt0000003|2       |nm1770680|producer       |producer               |null          |\n",
            "|tt0000003|3       |nm1335271|composer       |null                   |null          |\n",
            "|tt0000003|4       |nm5442200|editor         |null                   |null          |\n",
            "|tt0000004|1       |nm0721526|director       |null                   |null          |\n",
            "|tt0000004|2       |nm1335271|composer       |null                   |null          |\n",
            "|tt0000005|1       |nm0443482|actor          |null                   |[\"Blacksmith\"]|\n",
            "|tt0000005|2       |nm0653042|actor          |null                   |[\"Assistant\"] |\n",
            "|tt0000005|3       |nm0005690|director       |null                   |null          |\n",
            "|tt0000005|4       |nm0249379|producer       |producer               |null          |\n",
            "|tt0000006|1       |nm0005690|director       |null                   |null          |\n",
            "|tt0000007|1       |nm0179163|actor          |null                   |null          |\n",
            "|tt0000007|2       |nm0183947|actor          |null                   |null          |\n",
            "|tt0000007|3       |nm0005690|director       |null                   |null          |\n",
            "|tt0000007|4       |nm0374658|director       |null                   |null          |\n",
            "+---------+--------+---------+---------------+-----------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read title.episode"
      ],
      "metadata": {
        "id": "3R5vG_hiXUzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_title_episode = '/content/drive/MyDrive/GD/input_files/title.episode/data.tsv'\n",
        "\n",
        "schema_title_episode = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                    t.StructField('ParentTconst', t.StringType(), True),\n",
        "                                    t.StructField('SeasonNumber', t.IntegerType(), True),\n",
        "                                    t.StructField('EpisodeNumber ', t.IntegerType(), True),\n",
        "                                  ])\n",
        "\n",
        "\n",
        "title_episode_df = read_csv(path_title_episode, schema_title_episode, spark_session)\n",
        "title_episode_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "pGacPN1KVNrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab07ff5-7095-416a-fe4c-baa6601e6ddb"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------------+--------------+\n",
            "|Tconst   |ParentTconst|SeasonNumber|EpisodeNumber |\n",
            "+---------+------------+------------+--------------+\n",
            "|tt0020666|tt15180956  |1           |2             |\n",
            "|tt0020829|tt15180956  |1           |1             |\n",
            "|tt0021166|tt15180956  |1           |3             |\n",
            "|tt0021612|tt15180956  |2           |2             |\n",
            "|tt0021655|tt15180956  |2           |5             |\n",
            "|tt0021663|tt15180956  |2           |6             |\n",
            "|tt0021664|tt15180956  |2           |4             |\n",
            "|tt0021701|tt15180956  |2           |1             |\n",
            "|tt0021802|tt15180956  |2           |11            |\n",
            "|tt0022009|tt15180956  |2           |10            |\n",
            "|tt0022031|tt15180956  |2           |8             |\n",
            "|tt0022127|tt15180956  |2           |9             |\n",
            "|tt0022152|tt15180956  |2           |7             |\n",
            "|tt0022385|tt15180956  |2           |3             |\n",
            "|tt0022604|tt15180956  |3           |8             |\n",
            "|tt0022610|tt15180956  |3           |10            |\n",
            "|tt0022631|tt15180956  |3           |1             |\n",
            "|tt0022666|tt15180956  |3           |11            |\n",
            "|tt0022667|tt15180956  |3           |17            |\n",
            "|tt0022668|tt15180956  |3           |15            |\n",
            "+---------+------------+------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read title.crew"
      ],
      "metadata": {
        "id": "OVFBTwPMYpvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_title_crew = '/content/drive/MyDrive/GD/input_files/title.crew/data.tsv'\n",
        "\n",
        "schema_title_crew = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                    t.StructField('Directors', t.StringType(), True),\n",
        "                                    t.StructField('Writers ', t.StringType(), True),\n",
        "                                  ])\n",
        "\n",
        "\n",
        "title_crew_df = read_csv(path_title_crew, schema_title_crew, spark_session)\n",
        "title_crew_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "rIpH8dZ3VN3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22399969-4362-444d-b022-bd330c735668"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+---------+\n",
            "|Tconst   |Directors          |Writers  |\n",
            "+---------+-------------------+---------+\n",
            "|tt0000001|nm0005690          |null     |\n",
            "|tt0000002|nm0721526          |null     |\n",
            "|tt0000003|nm0721526          |null     |\n",
            "|tt0000004|nm0721526          |null     |\n",
            "|tt0000005|nm0005690          |null     |\n",
            "|tt0000006|nm0005690          |null     |\n",
            "|tt0000007|nm0005690,nm0374658|null     |\n",
            "|tt0000008|nm0005690          |null     |\n",
            "|tt0000009|nm0085156          |nm0085156|\n",
            "|tt0000010|nm0525910          |null     |\n",
            "|tt0000011|nm0804434          |null     |\n",
            "|tt0000012|nm0525910,nm0525908|null     |\n",
            "|tt0000013|nm0525910          |null     |\n",
            "|tt0000014|nm0525910          |null     |\n",
            "|tt0000015|nm0721526          |null     |\n",
            "|tt0000016|nm0525910          |null     |\n",
            "|tt0000017|nm1587194,nm0804434|null     |\n",
            "|tt0000018|nm0804434          |null     |\n",
            "|tt0000019|nm0932055          |null     |\n",
            "|tt0000020|nm0010291          |null     |\n",
            "+---------+-------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read title.ratings"
      ],
      "metadata": {
        "id": "UFcUZdGCYqaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_title_ratings = '/content/drive/MyDrive/GD/input_files/title.ratings/data.tsv'\n",
        "\n",
        "schema_title_ratings = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                     t.StructField('AverageRating', t.FloatType(), True),\n",
        "                                     t.StructField('NumVotes', t.IntegerType(), True),\n",
        "                                   ])\n",
        "\n",
        "\n",
        "title_ratings_df = read_csv(path_title_ratings, schema_title_ratings, spark_session)\n",
        "title_ratings_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "7sTC8Bt0VPR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4bb77c-c133-423b-fc5e-db836cda473b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+--------+\n",
            "|Tconst   |AverageRating|NumVotes|\n",
            "+---------+-------------+--------+\n",
            "|tt0000001|5.7          |1899    |\n",
            "|tt0000002|5.9          |254     |\n",
            "|tt0000003|6.5          |1692    |\n",
            "|tt0000004|5.7          |166     |\n",
            "|tt0000005|6.2          |2509    |\n",
            "|tt0000006|5.2          |172     |\n",
            "|tt0000007|5.4          |784     |\n",
            "|tt0000008|5.4          |2037    |\n",
            "|tt0000009|5.3          |197     |\n",
            "|tt0000010|6.9          |6863    |\n",
            "|tt0000011|5.3          |352     |\n",
            "|tt0000012|7.4          |11768   |\n",
            "|tt0000013|5.7          |1817    |\n",
            "|tt0000014|7.1          |5276    |\n",
            "|tt0000015|6.2          |1015    |\n",
            "|tt0000016|5.9          |1421    |\n",
            "|tt0000017|4.6          |310     |\n",
            "|tt0000018|5.3          |569     |\n",
            "|tt0000019|5.2          |31      |\n",
            "|tt0000020|4.8          |339     |\n",
            "+---------+-------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Get all titles of series/movies etc. that are available in Ukrainian."
      ],
      "metadata": {
        "id": "8lzHv-A_S4qh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df1(df, column, value,target_column):\n",
        "  \"\"\"\n",
        "  Get all titles of series/movies etc. that are available in Ukrainian.\n",
        "  \n",
        "  Input:\n",
        "    df - dataframe,\n",
        "    column - column that is filtered,\n",
        "    value - the desired value in the column,\n",
        "    target_column - mandatory column\n",
        "  \n",
        "  Output:\n",
        "    filtered dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  df = df.filter(f.col(column) == value)\n",
        "  return df.na.drop(subset=[target_column])\n",
        "\n",
        "col = \"Region\"\n",
        "value = \"UA\"\n",
        "target_column = \"Title\"\n",
        "\n",
        "filtered_title_akas_df = get_filter_df1(title_akas_df, col, value,target_column)\n",
        "filtered_title_akas_df.show()"
      ],
      "metadata": {
        "id": "6q-ZkV0EB66Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d95e97f1-1733-47fc-ffaa-c059e15b780c"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+--------------------+------+--------+-----------+----------+----------------+\n",
            "|  TitleId|Ordering|               Title|Region|Language|      Types|Attributes|IsOriginalTitle |\n",
            "+---------+--------+--------------------+------+--------+-----------+----------+----------------+\n",
            "|tt0000001|       1|          Карменсіта|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000003|       4|        Бідний П'єро|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000005|       2|    Ковальська сцена|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000008|       9|   Чхання Фреда Отта|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000010|      10|Вихід робітників ...|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000012|      26|Прибуття потяга н...|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000013|      13|Прибуття делегаті...|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000014|      19| Политий поливальник|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000015|       6|     Навколо кабінки|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000022|       5|              Ковалі|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000023|       2|     Морське купання|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000026|      12|      Партія в карти|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000027|       1|Площа Кордельє в ...|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000028|       4|Виловлювання черв...|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000029|      17|  Сніданок немовляти|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000031|       8|Стрибок через бре...|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000033|      11|       Вольтижування|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000041|       5|        Гра в сніжки|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000070|      16|    Зруйнування муру|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000091|       5|       Замок диявола|    UA|    null|imdbDisplay|      null|               0|\n",
            "+---------+--------+--------------------+------+--------+-----------+----------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Get the list of people’s names, who were born in the 19th century."
      ],
      "metadata": {
        "id": "ChGzMdC6S6sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df2(df, column, values, target_column):\n",
        "  \"\"\"\n",
        "  Get the list of people’s names, who were born in the 19th century.\n",
        "  \n",
        "  Input:\n",
        "    df - dataframe,\n",
        "    column - column that is filtered,\n",
        "    values - the desired values in the column,\n",
        "    target_column - mandatory column\n",
        "  \n",
        "  Output:\n",
        "    filtered dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  df = df.filter((f.col(column) >= values[0]) & (f.col(column) <= values[1]))\n",
        "  return df.na.drop(subset=[target_column])\n",
        "\n",
        "col = \"BirthYear\"\n",
        "values = [1801, 1900] # 19th century.\n",
        "target_column = 'PrimaryName'\n",
        "\n",
        "filtered_name_basics_df = get_filter_df2(name_basics_df, col, values, target_column)\n",
        "filtered_name_basics_df.show()"
      ],
      "metadata": {
        "id": "3FvXQtPeRtmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c322565-e7a9-49de-f669-8ed277b8fcc7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+---------+---------+--------------------+--------------------+\n",
            "|  TitleId|       PrimaryName|BirthYear|DeathYear|   PrimaryProfession|      KnownForTitles|\n",
            "+---------+------------------+---------+---------+--------------------+--------------------+\n",
            "|nm0000001|      Fred Astaire|     1899|     1987|soundtrack,actor,...|tt0072308,tt00531...|\n",
            "|nm0000007|   Humphrey Bogart|     1899|     1957|actor,soundtrack,...|tt0043265,tt00373...|\n",
            "|nm0000010|      James Cagney|     1899|     1986|actor,soundtrack,...|tt0042041,tt00355...|\n",
            "|nm0000033|  Alfred Hitchcock|     1899|     1980|director,producer...|tt0053125,tt00542...|\n",
            "|nm0000036|     Buster Keaton|     1895|     1966|actor,writer,dire...|tt0016332,tt00153...|\n",
            "|nm0000050|      Groucho Marx|     1890|     1977|soundtrack,actor,...|tt0028772,tt00197...|\n",
            "|nm0000055|     Alfred Newman|     1900|     1970|music_department,...|tt0065377,tt00560...|\n",
            "|nm0000064|Edward G. Robinson|     1893|     1973|actor,soundtrack,...|tt0040506,tt00389...|\n",
            "|nm0000068|    Randolph Scott|     1898|     1987|actor,producer,so...|tt0029284,tt00564...|\n",
            "|nm0000070|       Max Steiner|     1888|     1971|music_department,...|tt0031381,tt00345...|\n",
            "|nm0000075|     Spencer Tracy|     1900|     1967|    actor,soundtrack|tt0047849,tt00539...|\n",
            "|nm0000082|      Victor Young|     1900|     1956|music_department,...|tt0048960,tt01190...|\n",
            "|nm0000122|   Charles Chaplin|     1889|     1977|writer,soundtrack...|tt0018773,tt00448...|\n",
            "|nm0000252|      Robert Ellis|     1892|     1974|actor,director,wr...|tt0030778,tt00325...|\n",
            "|nm0000253|      Robert Ellis|     1888|     1935|art_director,misc...|tt0014515,tt00264...|\n",
            "|nm0000311|       Annie Rosar|     1888|     1963|  actress,soundtrack|tt0052996,tt00343...|\n",
            "|nm0000320|       Luis Buñuel|     1900|     1983|writer,director,a...|tt0068361,tt00567...|\n",
            "|nm0000406|         John Ford|     1894|     1973|director,producer...|tt0045061,tt00319...|\n",
            "|nm0000428|     D.W. Griffith|     1875|     1948|director,writer,p...|tt0006864,tt00104...|\n",
            "|nm0000472|     Boris Karloff|     1887|     1969|    actor,soundtrack|tt0023194,tt00248...|\n",
            "+---------+------------------+---------+---------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Get titles of all movies that last more than 2 hours."
      ],
      "metadata": {
        "id": "PfXwENhIS7HR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df3(df, column1, value1, column2, value2, target_column):\n",
        "  \"\"\"\n",
        "  Get titles of all movies that last more than 2 hours.\n",
        "\n",
        "  Input:\n",
        "    df - dataframe,\n",
        "    column1 - column that is filtered (RuntimeMinutes),\n",
        "    value1 - the desired value in the column,\n",
        "    column2 - column that is filtered (TitleType),\n",
        "    value2 - the desired value in the column,\n",
        "    target_column - mandatory column\n",
        "  \n",
        "  Output:\n",
        "    filtered dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  df = df.filter((f.col(column1) > value1) & (f.col(column2).isin(value2)))\n",
        "  return df.na.drop(subset=target_column)\n",
        "\n",
        "col1 = \"RuntimeMinutes\"\n",
        "value1 = 120 # 2 hours in minutes\n",
        "col2 = \"TitleType\"\n",
        "value2 = ['movie', 'tvMovie']\n",
        "target_column = ['PrimaryTitle', 'OriginalTitle']\n",
        "\n",
        "filtered_title_basics_df = get_filter_df3(title_basics_df, col1, value1, col2, value2, target_column)\n",
        "filtered_title_basics_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "lunU9HHnT8_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda5da05-159b-413a-baa9-15ddbd831a6d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+---------------------------------------+---------------------------------------+-------+---------+-------+--------------+-----------------------+\n",
            "|Tconst   |TitleType|PrimaryTitle                           |OriginalTitle                          |IsAdult|StartYear|EndYear|RuntimeMinutes|Genres                 |\n",
            "+---------+---------+---------------------------------------+---------------------------------------+-------+---------+-------+--------------+-----------------------+\n",
            "|tt0002574|movie    |What Happened to Mary                  |What Happened to Mary                  |0      |1912     |null   |150           |Action,Drama,Thriller  |\n",
            "|tt0002605|movie    |The Adventures of Kathlyn              |The Adventures of Kathlyn              |0      |1913     |null   |300           |Adventure              |\n",
            "|tt0002646|movie    |Atlantis                               |Atlantis                               |0      |1913     |null   |121           |Drama                  |\n",
            "|tt0002898|movie    |Germinal; or, The Toll of Labor        |Germinal                               |0      |1913     |null   |150           |Drama                  |\n",
            "|tt0003159|movie    |Les Misérables, Part 2: Fantine        |Les misérables - Époque 2: Fantine     |0      |1913     |null   |300           |Drama                  |\n",
            "|tt0003596|movie    |The Active Life of Dolly of the Dailies|The Active Life of Dolly of the Dailies|0      |1914     |null   |170           |Drama                  |\n",
            "|tt0003675|movie    |The Beloved Adventurer                 |The Beloved Adventurer                 |0      |1914     |null   |450           |Adventure              |\n",
            "|tt0003740|movie    |Cabiria                                |Cabiria                                |0      |1914     |null   |148           |Adventure,Drama,History|\n",
            "|tt0003883|movie    |L'enfant de Paris                      |L'enfant de Paris                      |0      |1913     |null   |124           |Crime,Drama            |\n",
            "|tt0003897|movie    |The Exploits of Elaine                 |The Exploits of Elaine                 |0      |1914     |null   |220           |Action                 |\n",
            "|tt0004052|movie    |The Hazards of Helen                   |The Hazards of Helen                   |0      |1914     |null   |1428          |Action                 |\n",
            "|tt0004272|movie    |Lucille Love: The Girl of Mystery      |Lucille Love: The Girl of Mystery      |0      |1914     |null   |300           |Action                 |\n",
            "|tt0004313|movie    |The Master Key                         |The Master Key                         |0      |1914     |null   |310           |Action,Adventure,Drama |\n",
            "|tt0004465|movie    |The Perils of Pauline                  |The Perils of Pauline                  |0      |1914     |null   |199           |Action,Adventure,Drama |\n",
            "|tt0004483|movie    |The Port of Missing Men                |The Port of Missing Men                |0      |1914     |null   |139           |Drama                  |\n",
            "|tt0004594|movie    |El signo de la tribu                   |El signo de la tribu                   |0      |1914     |null   |219           |null                   |\n",
            "|tt0004727|movie    |The Trey o' Hearts                     |The Trey o' Hearts                     |0      |1914     |null   |310           |Adventure              |\n",
            "|tt0004972|movie    |The Birth of a Nation                  |The Birth of a Nation                  |0      |1915     |null   |195           |Drama,History,War      |\n",
            "|tt0004974|movie    |The Black Box                          |The Black Box                          |0      |1915     |null   |195           |Drama,Sci-Fi           |\n",
            "|tt0005005|movie    |The Broken Coin                        |The Broken Coin                        |0      |1915     |null   |440           |Adventure,Mystery      |\n",
            "+---------+---------+---------------------------------------+---------------------------------------+-------+---------+-------+--------------+-----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Get names of people, corresponding movies/series and characters they played in those films. "
      ],
      "metadata": {
        "id": "CvaQCTDWS7kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df4(name_basics_df, title_basics_df, title_principals_df, \n",
        "                   col_id, col_id_name_basics, col_name, col_film, col_char):\n",
        "  \"\"\"\n",
        "  Get names of people, corresponding movies/series and characters they played in those films.\n",
        "  \n",
        "  Input:\n",
        "    name_basics_df, title_basics_df, title_principals_df - dataframes,\n",
        "    col_id - the name of the column by which the dataframes will be connected\n",
        "    col_id_name_basics - name of the column in the dataframe name_basics by which the dataframes will be connected\n",
        "    col_name - mandatory column in the name_basics_df\n",
        "    col_film - mandatory column in the title_basics_df\n",
        "    col_char - mandatory column in the title_principals_df\n",
        "  \n",
        "  Output:\n",
        "    filtered dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  new_df1 = name_basics_df.select([col_id_name, col_name])\n",
        "  new_df2 = title_basics_df.select([col_id, col_film[0], col_film[1]])\n",
        "  new_df3 = title_principals_df.select([col_id, col_char])\n",
        "  \n",
        "  new_df1 = new_df1.select([f.split(f.col(col_id_name),\",\").alias(col_id_name), col_name])\n",
        "  new_df1 = new_df1.select([f.explode(new_df1[col_id_name]).alias(col_id_name), new_df1[col_name]])\n",
        "  new_df3 = new_df3.withColumn( col_char, f.translate(f.col(col_char), '[\"]', \"\"))\n",
        "  # return new_df3\n",
        "\n",
        "  df4 = new_df1.join(new_df2, new_df1[col_id_name] ==  new_df2[col_id], \"inner\")\n",
        "  df4 = df4.join(new_df3, df4[col_id] ==  new_df3[col_id], \"inner\").drop(col_id)\n",
        "  df4 = df4.withColumnRenamed(col_id_name, col_id)\n",
        "  \n",
        "  return df4\n",
        "\n",
        "col_id = \"Tconst\"\n",
        "col_id_name = 'KnownForTitles'\n",
        "col_name = \"PrimaryName\"\n",
        "col_film = ['PrimaryTitle', 'OriginalTitle']\n",
        "col_char = 'Characters'\n",
        "\n",
        "\n",
        "result_df4  = get_filter_df4(name_basics_df, title_basics_df, title_principals_df, \n",
        "                        col_id, col_id_name, col_name, col_film, col_char)\n",
        "result_df4.show(truncate=False)"
      ],
      "metadata": {
        "id": "wWx4BWxx7m9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3008b33-46ad-49f0-f3e7-d9f3cab800ca"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------------+-------------------------------+-------------------------------+--------------+\n",
            "|Tconst   |PrimaryName     |PrimaryTitle                   |OriginalTitle                  |Characters    |\n",
            "+---------+----------------+-------------------------------+-------------------------------+--------------+\n",
            "|tt0000174|Jan Krízenecký  |Výstavní párkar a lepic plakátù|Výstavní párkar a lepic plakátù|Sausage Vendor|\n",
            "|tt0000174|Jan Krízenecký  |Výstavní párkar a lepic plakátù|Výstavní párkar a lepic plakátù|Sticker       |\n",
            "|tt0000174|Jan Krízenecký  |Výstavní párkar a lepic plakátù|Výstavní párkar a lepic plakátù|null          |\n",
            "|tt0000174|Ferdinand Gýra  |Výstavní párkar a lepic plakátù|Výstavní párkar a lepic plakátù|Sausage Vendor|\n",
            "|tt0000174|Ferdinand Gýra  |Výstavní párkar a lepic plakátù|Výstavní párkar a lepic plakátù|Sticker       |\n",
            "|tt0000174|Ferdinand Gýra  |Výstavní párkar a lepic plakátù|Výstavní párkar a lepic plakátù|null          |\n",
            "|tt0000305|Valentine Brouat|L'Habanera                     |L'Habanera                     |null          |\n",
            "|tt0000305|Valentine Brouat|L'Habanera                     |L'Habanera                     |null          |\n",
            "|tt0000451|Laura Bayley    |Mary Jane's Mishap             |Mary Jane's Mishap             |Mary Jane     |\n",
            "|tt0000451|Laura Bayley    |Mary Jane's Mishap             |Mary Jane's Mishap             |null          |\n",
            "|tt0000621|Gertie Potter   |That Fatal Sneeze              |That Fatal Sneeze              |Uncle         |\n",
            "|tt0000621|Gertie Potter   |That Fatal Sneeze              |That Fatal Sneeze              |Nephew        |\n",
            "|tt0000621|Gertie Potter   |That Fatal Sneeze              |That Fatal Sneeze              |null          |\n",
            "|tt0000621|Gertie Potter   |That Fatal Sneeze              |That Fatal Sneeze              |null          |\n",
            "|tt0000621|Thurston Harris |That Fatal Sneeze              |That Fatal Sneeze              |Uncle         |\n",
            "|tt0000621|Thurston Harris |That Fatal Sneeze              |That Fatal Sneeze              |Nephew        |\n",
            "|tt0000621|Thurston Harris |That Fatal Sneeze              |That Fatal Sneeze              |null          |\n",
            "|tt0000621|Thurston Harris |That Fatal Sneeze              |That Fatal Sneeze              |null          |\n",
            "|tt0000862|Schiøler Linck  |Faldgruben                     |Faldgruben                     |Doktor        |\n",
            "|tt0000862|Schiøler Linck  |Faldgruben                     |Faldgruben                     |Charles       |\n",
            "+---------+----------------+-------------------------------+-------------------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Get information about how many adult movies/series etc. there are per region. Get the top 100 of them from the region with the biggest count to the region with the smallest one."
      ],
      "metadata": {
        "id": "frAFbG0VS7-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df5(title_basics_df, title_akas_df, col1, col2, col_id1, col_id2):\n",
        "  \"\"\"\n",
        "  Get information about how many adult movies/series etc. there are per region. \n",
        "  Get the top 100 of them from the region with the biggest count to the region with the smallest one.\n",
        "\n",
        "  Input:\n",
        "    title_basics_df, title_akas_df - dataframes,\n",
        "    col_id1 - name of the column (id column) in the dataframe title_basics_df by which the dataframes will be connected\n",
        "    col_id2 - name of the column (id column) in the dataframe title_akas_df by which the dataframes will be connected\n",
        "    col1 - a column with an age description\n",
        "    col2 - region name column\n",
        "\n",
        "  Output:\n",
        "    filtered dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  joined_df = title_basics_df.join(title_akas_df, title_basics_df[col_id1] ==  title_akas_df[col_id2], \"inner\")\n",
        "  joined_df = joined_df.filter(f.col(col1) == 1)\n",
        "  joined_df = joined_df.na.drop(subset=[col1, col2])\n",
        "  return joined_df.groupBy(col2).count().orderBy('count', ascending=False).limit(100)\n",
        "\n",
        "col1 = 'IsAdult'\n",
        "col2 = 'Region'\n",
        "col_id1 = 'Tconst'\n",
        "col_id2 = 'TitleId'\n",
        "\n",
        "result_df5 = get_filter_df5(title_basics_df, title_akas_df, col1, col2, col_id1, col_id2)\n",
        "\n",
        "result_df5.show()"
      ],
      "metadata": {
        "id": "zoYPCHSiS6LM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4832336-678e-4e68-e5aa-5374e6643673"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|Region|count|\n",
            "+------+-----+\n",
            "|    US|93168|\n",
            "|    JP|21073|\n",
            "|    DE|12446|\n",
            "|    FR| 8035|\n",
            "|    ES| 6244|\n",
            "|    IT| 5944|\n",
            "|    CA| 5381|\n",
            "|    GB| 4455|\n",
            "|    VE| 3685|\n",
            "|    PT| 3508|\n",
            "|    IN| 3170|\n",
            "|   XWW| 2693|\n",
            "|    NL| 2025|\n",
            "|    BR| 1939|\n",
            "|    CZ| 1561|\n",
            "|    SE| 1381|\n",
            "|   XWG| 1170|\n",
            "|    HU|  866|\n",
            "|    GR|  860|\n",
            "|    DK|  808|\n",
            "+------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Get information about how many episodes in each TV Series. Get the top 50 of them starting from the TV Series with the biggest quantity of episodes."
      ],
      "metadata": {
        "id": "e9RmZDb8S8Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df6(title_episode_df, col_id, col_count):\n",
        "  \"\"\"\n",
        "  Get information about how many episodes in each TV Series. \n",
        "  Get the top 50 of them starting from the TV Series with the biggest quantity of episodes.\n",
        "\n",
        "  Input:\n",
        "    title_episode_df - dataframe,\n",
        "    col_id - column (id column) by which the data is grouped\n",
        "    col_count - series id column\n",
        "\n",
        "  Output:\n",
        "    filtered dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  new_df = title_episode_df.select([col_id, col_count])\n",
        "  return new_df.groupBy(col_id).count().orderBy('count', ascending=False).limit(50)\n",
        "\n",
        "col_id = \"ParentTconst\"\n",
        "col_count = \"Tconst\"\n",
        "\n",
        "result_df6  = get_filter_df6(title_episode_df, col_id, col_count)\n",
        "result_df6.show(truncate=False)"
      ],
      "metadata": {
        "id": "al7lG7SKPq8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bac055b-9d27-4296-d861-d829882eb39f"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "|ParentTconst|count|\n",
            "+------------+-----+\n",
            "|tt12164062  |18045|\n",
            "|tt0058796   |14559|\n",
            "|tt0069658   |12532|\n",
            "|tt0988827   |10674|\n",
            "|tt0053494   |10505|\n",
            "|tt0344642   |10015|\n",
            "|tt0270116   |9885 |\n",
            "|tt0055708   |9807 |\n",
            "|tt0363402   |9580 |\n",
            "|tt1985601   |9502 |\n",
            "|tt0068120   |9320 |\n",
            "|tt0380100   |9220 |\n",
            "|tt0088580   |9199 |\n",
            "|tt0283794   |9010 |\n",
            "|tt0434733   |9004 |\n",
            "|tt0092325   |8775 |\n",
            "|tt0159881   |8632 |\n",
            "|tt0283767   |8456 |\n",
            "|tt0068069   |8368 |\n",
            "|tt0439979   |8286 |\n",
            "+------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.\tGet 10 titles of the most popular movies/series etc. by each decade. "
      ],
      "metadata": {
        "id": "d-eWXTCsTPA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df7(title_basics_df, title_ratings_df, col_id1, col_id2, spark_session):\n",
        "  \"\"\"\n",
        "  Get 10 titles of the most popular movies/series etc. by each decade.\n",
        "\n",
        "  Input:\n",
        "    title_basics_df, title_ratings_df - dataframes,\n",
        "    col_id1 - name of the column (id column) in the dataframe title_basics_df by which the dataframes will be connected\n",
        "    col_id2 - name of the column (id column) in the dataframe title_ratings_df by which the dataframes will be connected\n",
        "    spark_session - spark_session\n",
        "\n",
        "  Output:\n",
        "    filtered dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  schema_result_df7 = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                    t.StructField('TitleType', t.StringType(), True),\n",
        "                                    t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                    t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                    t.StructField('StartYear', t.IntegerType(), True),\n",
        "                                    t.StructField('Decade', t.IntegerType(), True),\n",
        "                                    t.StructField('AverageRating', t.FloatType(), True),\n",
        "                                  ])\n",
        "  data_df7 = []\n",
        "  df7 = spark_session.createDataFrame(data = data_df7, schema = schema_result_df7)\n",
        "\n",
        "  result_df7 = title_basics_df.join(title_ratings_df, title_basics_df[col_id1] ==  title_ratings_df[col_id2], \"inner\").drop(col_id2)\n",
        "  result_df7 = result_df7.na.drop(subset=['PrimaryTitle', 'OriginalTitle', 'StartYear', 'AverageRating'])\n",
        "  result_df7 = result_df7.withColumn('Decade', ((f.col('StartYear')-1) / 10).cast('int'))\n",
        "  list_decades = result_df7.toPandas()['Decade'].unique().tolist()\n",
        "\n",
        "  for dec in list_decades:\n",
        "    df7 = (df7.union(result_df7.select([col_id1, 'TitleType', 'PrimaryTitle', 'OriginalTitle', 'StartYear', 'Decade', 'AverageRating'])\n",
        "                               .filter(f.col('Decade') == dec)\n",
        "                               .orderBy('AverageRating', ascending=False).limit(10)))\n",
        "  return df7\n",
        "\n",
        "col_id1 = 'Tconst'\n",
        "col_id2 = 'Tconst2'\n",
        "title_ratings_df = title_ratings_df.withColumnRenamed(col_id1, col_id2)\n",
        "\n",
        "result_df7 = get_filter_df7(title_basics_df, title_ratings_df, col_id1, col_id2, spark_session)\n",
        "result_df7.show(truncate=False)"
      ],
      "metadata": {
        "id": "qT4GP0ezS6Fx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66868399-7b9d-4865-c6b7-d5ac1901d964"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+---------+------+-------------+\n",
            "|Tconst   |TitleType|PrimaryTitle                                                                                                                                  |OriginalTitle                                                                                                                                 |StartYear|Decade|AverageRating|\n",
            "+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+---------+------+-------------+\n",
            "|tt0270202|short    |Another Picture Showing Demonstration of a Pneumatic Shell Riveter                                                                            |Another Picture Showing Demonstration of a Pneumatic Shell Riveter                                                                            |1900     |189   |8.4          |\n",
            "|tt0302466|short    |Demonstrating the Action of the Brown Hoisting and Conveying Machine in Unloading a Schooner of Iron Ore, and Loading the Material on the Cars|Demonstrating the Action of the Brown Hoisting and Conveying Machine in Unloading a Schooner of Iron Ore, and Loading the Material on the Cars|1900     |189   |8.1          |\n",
            "|tt0288497|short    |Demonstrating the Operation of the Harrington Rail Bonding System on the Line of the Coney Island and Brooklyn Railroad Co.                   |Demonstrating the Operation of the Harrington Rail Bonding System on the Line of the Coney Island and Brooklyn Railroad Co.                   |1900     |189   |7.9          |\n",
            "|tt0135696|short    |Four Heads Are Better Than One                                                                                                                |Un homme de têtes                                                                                                                             |1898     |189   |7.6          |\n",
            "|tt0000060|short    |Dancing Darkies                                                                                                                               |Dancing Darkies                                                                                                                               |1896     |189   |7.5          |\n",
            "|tt0000211|short    |The Astronomer's Dream; or, the Man in the Moon                                                                                               |La lune à un mètre                                                                                                                            |1898     |189   |7.5          |\n",
            "|tt2184114|short    |The Telephone No. 2                                                                                                                           |The Telephone No. 2                                                                                                                           |1898     |189   |7.4          |\n",
            "|tt1959451|short    |Let 'Em All Come                                                                                                                              |Let 'Em All Come                                                                                                                              |1899     |189   |7.4          |\n",
            "|tt0000012|short    |The Arrival of a Train                                                                                                                        |L'arrivée d'un train à La Ciotat                                                                                                              |1896     |189   |7.4          |\n",
            "|tt2374973|short    |Edinburgh                                                                                                                                     |Edinburgh                                                                                                                                     |1898     |189   |7.4          |\n",
            "|tt0210346|short    |Theodora                                                                                                                                      |Teodora imperatrice di Bisanzio                                                                                                               |1909     |190   |9.4          |\n",
            "|tt0418716|short    |Halloween                                                                                                                                     |Halloween                                                                                                                                     |1905     |190   |8.9          |\n",
            "|tt2042685|short    |The Nigger Boy's Revenge                                                                                                                      |The Nigger Boy's Revenge                                                                                                                      |1904     |190   |8.8          |\n",
            "|tt0235067|short    |World Series Baseball Game                                                                                                                    |World Series Baseball Game                                                                                                                    |1906     |190   |8.8          |\n",
            "|tt0458020|short    |La mort du pape Léon XIII                                                                                                                     |La mort du pape Léon XIII                                                                                                                     |1903     |190   |8.8          |\n",
            "|tt0425766|short    |Battle Royal                                                                                                                                  |Battle Royal                                                                                                                                  |1903     |190   |8.8          |\n",
            "|tt0759741|short    |Un coup de vent                                                                                                                               |Un coup de vent                                                                                                                               |1906     |190   |8.8          |\n",
            "|tt0448350|short    |Arsène Lupin                                                                                                                                  |Arsène Lupin                                                                                                                                  |1909     |190   |8.8          |\n",
            "|tt0135327|short    |The Dancing Nig                                                                                                                               |The Dancing Nig                                                                                                                               |1907     |190   |8.8          |\n",
            "|tt0757350|short    |Tu ne tueras point                                                                                                                            |Tu ne tueras point                                                                                                                            |1909     |190   |8.7          |\n",
            "+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+---------+------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.\tGet 10 titles of the most popular movies/series etc. by each genre."
      ],
      "metadata": {
        "id": "nI5Sfn_oTTCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df8(title_basics_df, title_ratings_df, col_id1, col_id2, spark_session):\n",
        "  \"\"\"\n",
        "  Get 10 titles of the most popular movies/series etc. by each genre.\n",
        "  \n",
        "  Input:\n",
        "    title_basics_df, title_ratings_df - dataframes,\n",
        "    col_id1 - name of the column (id column) in the dataframe title_basics_df by which the dataframes will be connected\n",
        "    col_id2 - name of the column (id column) in the dataframe title_ratings_df by which the dataframes will be connected\n",
        "    spark_session - spark_session\n",
        "\n",
        "  Output:\n",
        "    filtered dataframe\n",
        "  \"\"\"\n",
        "\n",
        "  schema_result_df8 = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                    t.StructField('TitleType', t.StringType(), True),\n",
        "                                    t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                    t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                    t.StructField('Genres', t.StringType(), True),\n",
        "                                    t.StructField('AverageRating', t.FloatType(), True),\n",
        "                                  ])\n",
        "  data_df8 = []\n",
        "  df8 = spark_session.createDataFrame(data = data_df8, schema = schema_result_df8)\n",
        "\n",
        "  result_df8 = title_basics_df.select([col_id1, 'TitleType', 'PrimaryTitle', 'OriginalTitle', f.split(f.col('Genres'),\",\").alias('Genres')])\n",
        "  result_df8 = result_df8.select([col_id1, 'TitleType', 'PrimaryTitle', 'OriginalTitle', f.explode(f.col('Genres')).alias('Genres')])\n",
        "  \n",
        "  result_df8 = result_df8.join(title_ratings_df, result_df8[col_id1] ==  title_ratings_df[col_id2], \"inner\").drop(col_id2)\n",
        "  result_df8 = result_df8.na.drop(subset=['PrimaryTitle', 'OriginalTitle', 'Genres', 'AverageRating'])\n",
        "  list_genres = result_df8.toPandas()['Genres'].unique().tolist()\n",
        "\n",
        "  for gen in list_genres:\n",
        "    df8 = (df8.union(result_df8.select([col_id1, 'TitleType', 'PrimaryTitle', 'OriginalTitle', 'Genres', 'AverageRating'])\n",
        "                               .filter(f.col('Genres') == gen)\n",
        "                               .orderBy('AverageRating', ascending=False).limit(10)))\n",
        "\n",
        "  return df8\n",
        "\n",
        "\n",
        "col_id1 = 'Tconst'\n",
        "col_id2 = 'Tconst2'\n",
        "title_ratings_df = title_ratings_df.withColumnRenamed(col_id1, col_id2)\n",
        "\n",
        "result_df8 = get_filter_df8(title_basics_df, title_ratings_df, col_id1, col_id2, spark_session)\n",
        "result_df8.show(truncate=False)"
      ],
      "metadata": {
        "id": "mv3bEST0-yZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b01b2c-ce85-4d4d-c5c7-16c7613128a3"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+-----------------------------------------+-----------------------------------------+---------+-------------+\n",
            "|Tconst    |TitleType|PrimaryTitle                             |OriginalTitle                            |Genres   |AverageRating|\n",
            "+----------+---------+-----------------------------------------+-----------------------------------------+---------+-------------+\n",
            "|tt1132924 |tvEpisode|Goth to Have Better Friends/Wax Attacks  |Goth to Have Better Friends/Wax Attacks  |Animation|10.0         |\n",
            "|tt1306434 |tvEpisode|Creepie Friday/The Final Curtain         |Creepie Friday/The Final Curtain         |Animation|10.0         |\n",
            "|tt1145947 |tvEpisode|Calling All Domos                        |Calling All Domos                        |Animation|10.0         |\n",
            "|tt1147818 |tvEpisode|One Week Later                           |One Week Later                           |Animation|10.0         |\n",
            "|tt0955930 |tvEpisode|Daishugeki! Team X vs. Imperial DG       |Daishugeki! Team X vs. Imperial DG       |Animation|10.0         |\n",
            "|tt1152810 |tvEpisode|The Lesson                               |The Lesson                               |Animation|10.0         |\n",
            "|tt0635627 |tvEpisode|Abel's Island                            |Abel's Island                            |Animation|10.0         |\n",
            "|tt12539164|tvEpisode|Sleepytime                               |Sleepytime                               |Animation|10.0         |\n",
            "|tt12587528|video    |Junga the Dancing Yeti                   |Junga the Dancing Yeti                   |Animation|10.0         |\n",
            "|tt0635631 |tvEpisode|The Fool of the World and the Flying Ship|The Fool of the World and the Flying Ship|Animation|10.0         |\n",
            "|tt0355468 |short    |The Birdman                              |Fågelmannen                              |Short    |10.0         |\n",
            "|tt0343731 |short    |Bare Island                              |Goli otok                                |Short    |10.0         |\n",
            "|tt0323536 |short    |The Outlands                             |The Outlands                             |Short    |10.0         |\n",
            "|tt0116083 |short    |Desert                                   |Desert                                   |Short    |10.0         |\n",
            "|tt0324200 |video    |Tenkisti iz Nustra                       |Tenkisti iz Nustra                       |Short    |10.0         |\n",
            "|tt0299823 |short    |Saving Sister Aimee                      |Saving Sister Aimee                      |Short    |10.0         |\n",
            "|tt0325273 |video    |Doli: The Fragments of My Chilhood       |Doli - Krhotine moga djetinstva          |Short    |10.0         |\n",
            "|tt0281732 |short    |Closed for Business                      |Closed for Business                      |Short    |10.0         |\n",
            "|tt0334523 |short    |Tongue                                   |Tongue                                   |Short    |10.0         |\n",
            "|tt0176240 |short    |The Touch                                |The Touch                                |Short    |10.0         |\n",
            "+----------+---------+-----------------------------------------+-----------------------------------------+---------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save data\n"
      ],
      "metadata": {
        "id": "1kcPTxdt-x_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save1 = f'/content/drive/MyDrive/GD/output_files/result_df1.csv'\n",
        "write_csv(filtered_title_akas_df, path_to_save1)"
      ],
      "metadata": {
        "id": "HmNjed25q1Fh"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save2 = f'/content/drive/MyDrive/GD/output_files/result_df2.csv'\n",
        "write_csv(filtered_name_basics_df, path_to_save2)"
      ],
      "metadata": {
        "id": "z4cGQJtO2HKK"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save3 = f'/content/drive/MyDrive/GD/output_files/result_df3.csv'\n",
        "write_csv(filtered_title_basics_df, path_to_save3)"
      ],
      "metadata": {
        "id": "YjIo4KQw4rEM"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save4 = f'/content/drive/MyDrive/GD/output_files/result_df4.csv'\n",
        "write_csv(result_df4, path_to_save4)"
      ],
      "metadata": {
        "id": "Tjjl6SGY7m9F"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save5 = f'/content/drive/MyDrive/GD/output_files/result_df5.csv'\n",
        "write_csv(result_df5, path_to_save5)"
      ],
      "metadata": {
        "id": "6Nj_8NVJ_YkQ"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save6 = f'/content/drive/MyDrive/GD/output_files/result_df6.csv'\n",
        "write_csv(result_df6, path_to_save6)"
      ],
      "metadata": {
        "id": "gLDimEY-Sa_n"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save7 = f'/content/drive/MyDrive/GD/output_files/result_df7.csv'\n",
        "write_csv(result_df7, path_to_save7)"
      ],
      "metadata": {
        "id": "eJLdbXWZS5-h"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save8 = f'/content/drive/MyDrive/GD/output_files/result_df8.csv'\n",
        "write_csv(result_df8, path_to_save8)"
      ],
      "metadata": {
        "id": "a9J1xmdL20cA"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unittests\n"
      ],
      "metadata": {
        "id": "5NgL4x4JXk-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestFilters(unittest.TestCase):\n",
        "  \n",
        "  @classmethod\n",
        "  def setUpClass(cls):\n",
        "    cls.spark = (SparkSession\n",
        "                     .builder\n",
        "                     .master(\"local[*]\")\n",
        "                     .appName(\"Unit-tests\")\n",
        "                     .getOrCreate())\n",
        "\n",
        "  @classmethod\n",
        "  def tearDownClass(cls):\n",
        "    cls.spark.stop()\n",
        "\n",
        "  def test_get_filter_df1(self):\n",
        "    '''Test case function for 1 task'''\n",
        "    input_schema_task1 = t.StructType([t.StructField('TitleId', t.StringType(), True),\n",
        "                                 t.StructField('Ordering', t.IntegerType(), True),\n",
        "                                 t.StructField('Title', t.StringType(), True),\n",
        "                                 t.StructField('Region', t.StringType(), True),\n",
        "                                 t.StructField('Language', t.StringType(), True),\n",
        "                                 t.StructField('Types', t.StringType(), True),\n",
        "                                 t.StructField('Attributes', t.StringType(), True),\n",
        "                                 t.StructField('IsOriginalTitle',t.IntegerType(),True),\n",
        "                               ])\n",
        "    input_data_task1 = [\n",
        "          ('tt0000001',1, 'Карменсіта', 'UA', None, 'imdbDisplay', None, 0),\n",
        "          ('tt0000002',2, 'Καρμενσίτα', 'GR', None, 'imdbDisplay', 'literal title', 0),\n",
        "          ('tt0000003',3, 'Carmencita', 'DE', None, 'imdbDisplay', None, 0),\n",
        "          ('tt0000004',4, 'Carmencita', 'HU', None, 'imdbDisplay', None, 0),\n",
        "          ('tt0000005',5, 'Carmencita', 'US', None, 'imdbDisplay', None, 0),\n",
        "    ]\n",
        "    input_df1 = self.spark.createDataFrame(data = input_data_task1, schema = input_schema_task1)\n",
        "    \n",
        "    expected_data_task1 = [('tt0000001',1, 'Карменсіта', 'UA', None, 'imdbDisplay', None, 0),]\n",
        "    \n",
        "    col = \"Region\"\n",
        "    value = \"UA\"\n",
        "    target_column = \"Title\"\n",
        "\n",
        "    transformed_df = get_filter_df1(input_df1, col, value,target_column)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task1, schema = input_schema_task1)\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "    \n",
        "\n",
        "  def test_get_filter_df2(self):\n",
        "    '''Test case function for 2 task'''\n",
        "    input_schema_task2 = t.StructType([t.StructField('TitleId', t.StringType(), True),\n",
        "                                       t.StructField('PrimaryName', t.StringType(), True),\n",
        "                                       t.StructField('BirthYear', t.IntegerType(), True),\n",
        "                                       t.StructField('DeathYear', t.IntegerType(), True),\n",
        "                                       t.StructField('PrimaryProfession', t.StringType(), True),\n",
        "                                       t.StructField('KnownForTitles', t.StringType(), True),\n",
        "    ])\n",
        "\n",
        "    input_data_task2 = [\n",
        "          ('nm0000001','Fred Astaire', 1899, 1987, 'soundtrack,actor,miscellaneous', 'tt0072308,tt0053137,tt0050419,tt0031983'),\n",
        "          ('nm0000002','Lauren Bacall', 1924, 2014, 'actress,soundtrack', 'tt0038355,tt0117057,tt0071877,tt0037382'),\n",
        "          ('nm0000003','Brigitte Bardot', 1934, None, 'actress,soundtrack,music_department', 'tt0057345,tt0049189,tt0054452,tt0056404'),\n",
        "          ('nm0000004','John Belushi', 1949, 1982, 'actor,soundtrack,writer', 'tt0078723,tt0077975,tt0072562,tt0080455'),\n",
        "          ('nm0000005','Ingmar Bergman', 1918, 2007, 'writer,director,actor', 'tt0083922,tt0050986,tt0060827,tt0050976'),\n",
        "    ]\n",
        "\n",
        "    input_df2 = self.spark.createDataFrame(data = input_data_task2, schema = input_schema_task2)\n",
        "\n",
        "    expected_data_task2 = [('nm0000001','Fred Astaire', 1899, 1987, 'soundtrack,actor,miscellaneous', 'tt0072308,tt0053137,tt0050419,tt0031983')]\n",
        "    \n",
        "    col = \"BirthYear\"\n",
        "    values = [1801, 1900] # 19th century.\n",
        "    target_column = 'PrimaryName'\n",
        "\n",
        "    transformed_df = get_filter_df2(input_df2, col, values,target_column)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task2, schema = input_schema_task2)\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "\n",
        "  def test_get_filter_df3(self):\n",
        "    '''Test case function for 3 task'''\n",
        "    input_schema_task3 = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                            t.StructField('TitleType', t.StringType(), True),\n",
        "                            t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                            t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                            t.StructField('IsAdult', t.IntegerType(), True),\n",
        "                            t.StructField('StartYear', t.IntegerType(), True),\n",
        "                            t.StructField('EndYear', t.IntegerType(), True),\n",
        "                            t.StructField('RuntimeMinutes', t.IntegerType(), True),\n",
        "                            t.StructField('Genres', t.StringType(), True),\n",
        "    ])\n",
        "\n",
        "    input_data_task3 = [\n",
        "          ('tt0002574','movie', 'What Happened to Mary', 'What Happened to Mary', 0, 1912, None, 110, 'Action,Drama,Thriller'),\n",
        "          ('tt0002605','movie', 'The Adventures of Kathlyn', 'The Adventures of Kathlyn', 0, 1915, None, 300, 'Adventure'),\n",
        "          ('tt0002646','short', 'Atlantis', 'Atlantis', 0, 1944, None, 140, 'Drama'),\n",
        "\n",
        "    ]\n",
        "\n",
        "    input_df3 = self.spark.createDataFrame(data = input_data_task3, schema = input_schema_task3)\n",
        "\n",
        "    expected_data_task3 = [('tt0002605','movie', 'The Adventures of Kathlyn', 'The Adventures of Kathlyn', 0, 1915, None, 300, 'Adventure'),]\n",
        "    \n",
        "    col1 = \"RuntimeMinutes\"\n",
        "    value1 = 120 # 2 hours in minutes\n",
        "    col2 = \"TitleType\"\n",
        "    value2 = ['movie', 'tvMovie']\n",
        "    target_column = ['PrimaryTitle', 'OriginalTitle']\n",
        "\n",
        "    transformed_df = get_filter_df3(input_df3, col1, value1, col2, value2, target_column)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task3, schema = input_schema_task3)\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "\n",
        "  def test_get_filter_df4(self):\n",
        "    '''Test case function for 4 task'''\n",
        "    schema_name_basics = t.StructType([t.StructField('TitleId', t.StringType(), True),\n",
        "                                      t.StructField('PrimaryName', t.StringType(), True),\n",
        "                                      t.StructField('BirthYear', t.IntegerType(), True),\n",
        "                                      t.StructField('DeathYear', t.IntegerType(), True),\n",
        "                                      t.StructField('PrimaryProfession', t.StringType(), True),\n",
        "                                      t.StructField('KnownForTitles', t.StringType(), True),\n",
        "                                      ])\n",
        "    schema_title_basics = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                        t.StructField('TitleType', t.StringType(), True),\n",
        "                                        t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                        t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                        t.StructField('IsAdult', t.IntegerType(), True),\n",
        "                                        t.StructField('StartYear', t.IntegerType(), True),\n",
        "                                        t.StructField('EndYear', t.IntegerType(), True),\n",
        "                                        t.StructField('RuntimeMinutes', t.IntegerType(), True),\n",
        "                                        t.StructField('Genres', t.StringType(), True),\n",
        "                                      ])\n",
        "    schema_title_principals = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                        t.StructField('Ordering', t.IntegerType(), True),\n",
        "                                        t.StructField('Nconst', t.StringType(), True),\n",
        "                                        t.StructField('Category', t.StringType(), True),\n",
        "                                        t.StructField('Job', t.StringType(), True),\n",
        "                                        t.StructField('Characters', t.StringType(), True),\n",
        "                                      ])\n",
        "    schema_expected4 = t.StructType([t.StructField('Tconst', t.StringType(), False),\n",
        "                                    t.StructField('PrimaryName', t.StringType(), True),\n",
        "                                    t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                    t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                    t.StructField('Characters', t.StringType(), True),\n",
        "                                  ])\n",
        "    \n",
        "    input_name_basics = [\n",
        "          ('nm0000001','Fred Astaire', 1899, 1987, 'soundtrack,actor,miscellaneous', 'tt0072308,tt0053137,tt0050419,tt0031983'),\n",
        "          ('nm0000002','Lauren Bacall', 1924, 2014, 'actress,soundtrack', 'tt0038355,tt0117057,tt0071877,tt0037382'),\n",
        "          ('nm0000003','Brigitte Bardot', 1934, None, 'actress,soundtrack,music_department', 'tt0057345,tt0049189,tt0054452,tt0056404'),\n",
        "          ('nm0000004','John Belushi', 1949, 1982, 'actor,soundtrack,writer', 'tt0078723,tt0077975,tt0072562,tt0080455'),\n",
        "          ('nm0000005','Ingmar Bergman', 1918, 2007, 'writer,director,actor', 'tt0083922,tt0050986,tt0060827,tt0050976'),\n",
        "    ]\n",
        "    input_title_basics = [\n",
        "          ('tt0072308','movie', 'What Happened to Mary', 'What Happened to Mary', 0, 1912, None, 110, 'Action,Drama,Thriller'),\n",
        "          ('tt0071877','movie', 'The Adventures of Kathlyn', 'The Adventures of Kathlyn', 0, 1915, None, 300, 'Adventure'),\n",
        "          ('tt0002646','short', 'Atlantis', 'Atlantis', 0, 1944, None, 140, 'Drama'),\n",
        "\n",
        "    ]\n",
        "    input_title_principals = [\n",
        "        \n",
        "          ('tt0072308',1, 'nm1588970', 'self', None, '[\"Self\"]'),\n",
        "          ('tt0071877',2, 'nm0005690', 'director', None, '[\"Blacksmith\"]'),\n",
        "          ('tt0000003',3, 'nm0374658', 'cinematographer', 'director of photography', None),\n",
        "\n",
        "    ]\n",
        "    expected_data_task4 = [\n",
        "        \n",
        "          ('tt0072308', 'Fred Astaire', 'What Happened to Mary', 'What Happened to Mary', 'Self'),\n",
        "          ('tt0071877', 'Lauren Bacall', 'The Adventures of Kathlyn', 'The Adventures of Kathlyn', 'Blacksmith'),\n",
        "\n",
        "    ]\n",
        "    name_basics_df = self.spark.createDataFrame(data = input_name_basics, schema = schema_name_basics)\n",
        "    title_basics_df = self.spark.createDataFrame(data = input_title_basics, schema = schema_title_basics)\n",
        "    title_principals_df = self.spark.createDataFrame(data = input_title_principals, schema = schema_title_principals)\n",
        "\n",
        "    col_id = \"Tconst\"\n",
        "    col_id_name = 'KnownForTitles'\n",
        "    col_name = \"PrimaryName\"\n",
        "    col_film = ['PrimaryTitle', 'OriginalTitle']\n",
        "    col_char = 'Characters'\n",
        "\n",
        "    transformed_df = get_filter_df4(name_basics_df, title_basics_df, title_principals_df, col_id, col_id_name, col_name, col_film, col_char)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task4, schema = schema_expected4)\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "\n",
        "  def test_get_filter_df5(self):\n",
        "    '''Test case function for 5 task'''\n",
        "\n",
        "    schema_title_basics = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                            t.StructField('TitleType', t.StringType(), True),\n",
        "                            t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                            t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                            t.StructField('IsAdult', t.IntegerType(), True),\n",
        "                            t.StructField('StartYear', t.IntegerType(), True),\n",
        "                            t.StructField('EndYear', t.IntegerType(), True),\n",
        "                            t.StructField('RuntimeMinutes', t.IntegerType(), True),\n",
        "                            t.StructField('Genres', t.StringType(), True),\n",
        "    ])\n",
        "    schema_title_akas = t.StructType([t.StructField('TitleId', t.StringType(), True),\n",
        "                                t.StructField('Ordering', t.IntegerType(), True),\n",
        "                                t.StructField('Title', t.StringType(), True),\n",
        "                                t.StructField('Region', t.StringType(), True),\n",
        "                                t.StructField('Language', t.StringType(), True),\n",
        "                                t.StructField('Types', t.StringType(), True),\n",
        "                                t.StructField('Attributes', t.StringType(), True),\n",
        "                                t.StructField('IsOriginalTitle ',t.IntegerType(),True),\n",
        "    ])\n",
        "    \n",
        "    schema_expected5 = t.StructType([t.StructField('Region', t.StringType(), True),\n",
        "                                    t.StructField('count', t.LongType(), False),\n",
        "                                  ])\n",
        "    \n",
        "\n",
        "    input_title_basics = [\n",
        "          ('tt0000001','short', 'Carmencita', 'Carmencita', 1, 1912, None, 110, 'Action,Drama,Thriller'),\n",
        "          ('tt0000002','short', 'Der Clown und seine Hunde', 'Der Clown und seine Hunde', 1, 1915, None, 300, 'Adventure'),\n",
        "          ('tt0000003','short', 'Poor Pierrot', 'Poor Pierrot', 0, 1944, None, 140, 'Drama'),\n",
        "\n",
        "    ]\n",
        "    input_title_akas = [\n",
        "          ('tt0000001',1, 'Карменсіта', 'UA', None, 'imdbDisplay', None, 0),\n",
        "          ('tt0000001',2, 'Καρμενσίτα', 'GR', None, 'imdbDisplay', 'literal title', 0),\n",
        "          ('tt0000001',3, 'Carmencita', 'DE', None, 'imdbDisplay', None, 0),\n",
        "          ('tt0000002',1, \"Клоун та його собаки\", 'UA', None, 'imdbDisplay', None, 0),\n",
        "          ('tt0000002',2, 'Der Clown und seine Hunde', 'DE', None, 'imdbDisplay', None, 0),\n",
        "          ('tt0000003',2, \"Бідний П'єро\", 'UA', None, 'imdbDisplay', None, 0),\n",
        "\n",
        "    ]\n",
        "\n",
        "    expected_data_task5 = [\n",
        "        \n",
        "          ('UA', 2),\n",
        "          ('DE', 2),\n",
        "          ('GR', 1),\n",
        "\n",
        "    ]\n",
        "    title_akas_df = self.spark.createDataFrame(data = input_title_akas, schema = schema_title_akas)\n",
        "    title_basics_df = self.spark.createDataFrame(data = input_title_basics, schema = schema_title_basics)\n",
        "\n",
        "\n",
        "    col1 = 'IsAdult'\n",
        "    col2 = 'Region'\n",
        "    col_id1 = 'Tconst'\n",
        "    col_id2 = 'TitleId'\n",
        "\n",
        "    transformed_df = get_filter_df5(title_basics_df, title_akas_df, col1, col2, col_id1, col_id2)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task5, schema = schema_expected5)\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "\n",
        "  def test_get_filter_df6(self):\n",
        "    '''Test case function for 6 task'''\n",
        "\n",
        "    schema_title_episode = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                    t.StructField('ParentTconst', t.StringType(), True),\n",
        "                                    t.StructField('SeasonNumber', t.IntegerType(), True),\n",
        "                                    t.StructField('EpisodeNumber ', t.IntegerType(), True),\n",
        "                                  ])\n",
        "    \n",
        "    schema_expected6 = t.StructType([t.StructField('ParentTconst', t.StringType(), True),\n",
        "                                    t.StructField('count', t.LongType(), False),\n",
        "                                  ])\n",
        "    \n",
        "    input_title_episode = [\n",
        "          ('tt0020666','tt15180956', 1, 1),\n",
        "          ('tt0020829','tt15180956', 1, 2),\n",
        "          ('tt0020823','tt15180956', 1, 3),\n",
        "          ('tt0020634','tt15180957', 1, 1),\n",
        "          ('tt0020833','tt15180957', 1, 2),\n",
        "          ('tt0020432','tt15180957', 1, 3),\n",
        "          ('tt0020334','tt15180957', 1, 4),\n",
        "          ('tt0020233','tt15180957', 1, 5),\n",
        "          ('tt0020132','tt15180957', 1, 6),\n",
        "          ('tt0120634','tt15180958', 1, 1),\n",
        "          ('tt0120833','tt15180958', 1, 2),\n",
        "          ('tt0120432','tt15180958', 1, 3),\n",
        "          ('tt0120334','tt15180958', 1, 4),\n",
        "          ('tt0120233','tt15180958', 1, 5),\n",
        "\n",
        "    ]\n",
        "\n",
        "    expected_data_task6 = [\n",
        "          ('tt15180956', 3),\n",
        "          ('tt15180957', 6),\n",
        "          ('tt15180958', 5),\n",
        "\n",
        "    ]\n",
        "    title_episode_df = self.spark.createDataFrame(data = input_title_episode, schema = schema_title_episode)\n",
        "\n",
        "    col_id = \"ParentTconst\"\n",
        "    col_count = \"Tconst\"\n",
        "\n",
        "    transformed_df = get_filter_df6(title_episode_df, col_id, col_count)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task6, schema = schema_expected6)\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "\n",
        "  def test_get_filter_df7(self):\n",
        "    '''Test case function for 7 task'''\n",
        "\n",
        "    schema_title_ratings = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                         t.StructField('AverageRating', t.FloatType(), True),\n",
        "                                         t.StructField('NumVotes', t.IntegerType(), True),\n",
        "                                        ])\n",
        "    \n",
        "    schema_title_basics = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                        t.StructField('TitleType', t.StringType(), True),\n",
        "                                        t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                        t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                        t.StructField('IsAdult', t.IntegerType(), True),\n",
        "                                        t.StructField('StartYear', t.IntegerType(), True),\n",
        "                                        t.StructField('EndYear', t.IntegerType(), True),\n",
        "                                        t.StructField('RuntimeMinutes', t.IntegerType(), True),\n",
        "                                        t.StructField('Genres', t.StringType(), True),\n",
        "                                      ])\n",
        "    \n",
        "    schema_expected7 = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                    t.StructField('TitleType', t.StringType(), True),\n",
        "                                    t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                    t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                    t.StructField('StartYear', t.IntegerType(), True),\n",
        "                                    t.StructField('Decade', t.IntegerType(), True),\n",
        "                                    t.StructField('AverageRating', t.FloatType(), True),\n",
        "                                     \n",
        "                                  ])\n",
        "\n",
        "    input_title_ratings = [\n",
        "        ('tt0000001', 5.9, 1899), \n",
        "        ('tt0000002', 5.8, 254),  \n",
        "        ('tt0000003', 5.7, 1692), \n",
        "        ('tt0000004', 5.6, 166),  \n",
        "        ('tt0000005', 5.5, 2509), \n",
        "        ('tt0000006', 5.4, 172),  \n",
        "        ('tt0000007', 5.3, 784),  \n",
        "        ('tt0000008', 5.2, 2037), \n",
        "        ('tt0000009', 5.1, 197),  \n",
        "        ('tt0000010', 6.9, 6863), \n",
        "        ('tt0000011', 7.0, 352), \n",
        "        ('tt0000012', 7.4, 11768),\n",
        "        ('tt0000013', 5.7, 1817),\n",
        "        ('tt0000014', 5.1, 5276),\n",
        "        ('tt0000015', 5.1, 5276),\n",
        "        ('tt0000016', 8.1, 5476),\n",
        "        ('tt0000017', 8.1, 5256),\n",
        "    ]\n",
        "\n",
        "    input_title_basics = [\n",
        "        ('tt0000001','short', 'name1', 'name1', 1, 1815, None, 300, 'Adventure'),\n",
        "        ('tt0000002','short', 'name2', 'name2', 0, 1816, None, 140, 'Drama'),\n",
        "        ('tt0000003','movie', 'name3', 'name3', 1, 1812, None, 110, 'Action,Drama,Thriller'),\n",
        "        ('tt0000004','short', 'name4', 'name4', 1, 1815, None, 300, 'Adventure'),\n",
        "        ('tt0000005','short', 'name5', 'name5', 0, 1811, None, 140, 'Drama'),\n",
        "        ('tt0000006','short', 'name6', 'name6', 1, 1812, None, 110, 'Action,Drama,Thriller'),\n",
        "        ('tt0000007','movie', 'name7', 'name7', 1, 1815, None, 300, 'Adventure'),\n",
        "        ('tt0000008','short', 'name8', 'name8', 0, 1811, None, 140, 'Drama'),\n",
        "        ('tt0000009','movie', 'name9', 'name9', 1, 1812, None, 110, 'Action,Drama,Thriller'),\n",
        "        ('tt0000010','short', 'name10', 'name10', 1, 1815, None, 300, 'Adventure'),\n",
        "        ('tt0000011','short', 'name11', 'name11', 0, 1811, None, 140, 'Drama'),\n",
        "        ('tt0000012','short', 'Carmencita', 'Carmencita', 1, 1912, None, 110, 'Action,Drama,Thriller'),\n",
        "        ('tt0000013','movie', 'Der Clown und seine Hunde', 'Der Clown und seine Hunde', 1, 1915, None, 300, 'Adventure'),\n",
        "        ('tt0000014','short', 'Poor Pierrot', 'Poor Pierrot', 0, 1916, None, 140, 'Drama'),\n",
        "        ('tt0000015','movie', 'Carmencita', 'Carmencita', 1, 1912, None, 110, 'Action,Drama,Thriller'),\n",
        "    ]\n",
        "    expected_data_task7 = [\n",
        "        ('tt0000011','short', 'name11', 'name11', 1811, 181, 7.0,),\n",
        "        ('tt0000010','short', 'name10', 'name10', 1815, 181, 6.9,),\n",
        "        ('tt0000001','short', 'name1', 'name1', 1815, 181, 5.9,),\n",
        "        ('tt0000002','short', 'name2', 'name2', 1816, 181, 5.8,),\n",
        "        ('tt0000003','movie', 'name3', 'name3', 1812, 181, 5.7,),\n",
        "        ('tt0000004','short', 'name4', 'name4', 1815, 181, 5.6,),\n",
        "        ('tt0000005','short', 'name5', 'name5', 1811, 181, 5.5,),\n",
        "        ('tt0000006','short', 'name6', 'name6', 1812, 181, 5.4,),\n",
        "        ('tt0000007','movie', 'name7', 'name7', 1815, 181, 5.3,),\n",
        "        ('tt0000008','short', 'name8', 'name8', 1811, 181, 5.2,),    \n",
        "        ('tt0000012','short', 'Carmencita', 'Carmencita', 1912, 191, 7.4),\n",
        "        ('tt0000013','movie', 'Der Clown und seine Hunde', 'Der Clown und seine Hunde', 1915, 191, 5.7),\n",
        "        ('tt0000014','short', 'Poor Pierrot', 'Poor Pierrot', 1916, 191, 5.1),\n",
        "        ('tt0000015','movie', 'Carmencita', 'Carmencita', 1912, 191, 5.1),\n",
        "    ]\n",
        "\n",
        "    title_ratings_df = self.spark.createDataFrame(data = input_title_ratings, schema = schema_title_ratings)\n",
        "    title_basics_df = self.spark.createDataFrame(data = input_title_basics, schema = schema_title_basics)\n",
        "\n",
        "    col_id1 = 'Tconst'\n",
        "    col_id2 = 'Tconst2'\n",
        "    title_ratings_df = title_ratings_df.withColumnRenamed(col_id1, col_id2)\n",
        "\n",
        "    transformed_df = get_filter_df7(title_basics_df, title_ratings_df, col_id1, col_id2, self.spark)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task7, schema = schema_expected7)\n",
        "\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "    # print('\\n', set(fields1), '\\n', set(fields2))\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "  \n",
        "  \n",
        "  def test_get_filter_df8(self):\n",
        "    '''Test case function for 8 task'''\n",
        "\n",
        "    schema_title_ratings = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                         t.StructField('AverageRating', t.FloatType(), True),\n",
        "                                         t.StructField('NumVotes', t.IntegerType(), True),\n",
        "                                        ])\n",
        "    \n",
        "    schema_title_basics = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                        t.StructField('TitleType', t.StringType(), True),\n",
        "                                        t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                        t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                        t.StructField('IsAdult', t.IntegerType(), True),\n",
        "                                        t.StructField('StartYear', t.IntegerType(), True),\n",
        "                                        t.StructField('EndYear', t.IntegerType(), True),\n",
        "                                        t.StructField('RuntimeMinutes', t.IntegerType(), True),\n",
        "                                        t.StructField('Genres', t.StringType(), True),\n",
        "                                      ])\n",
        "    \n",
        "    schema_expected8 = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                     t.StructField('TitleType', t.StringType(), True),\n",
        "                                     t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                     t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                     t.StructField('Genres', t.StringType(), True),\n",
        "                                     t.StructField('AverageRating', t.FloatType(), True),\n",
        "                                   ])\n",
        "\n",
        "    input_title_ratings = [\n",
        "        ('tt0000001', 5.9, 1899), \n",
        "        ('tt0000002', 6.8, 254),  \n",
        "        ('tt0000003', 5.7, 1692), \n",
        "        ('tt0000004', 5.6, 166),  \n",
        "        ('tt0000005', 5.5, 2509), \n",
        "        ('tt0000006', 5.4, 172),  \n",
        "        ('tt0000007', 5.3, 784),  \n",
        "        ('tt0000008', 5.2, 2037), \n",
        "        ('tt0000009', 5.1, 197),  \n",
        "        ('tt0000010', 6.9, 6863), \n",
        "        ('tt0000011', 7.0, 352), \n",
        "        ('tt0000012', 7.4, 11768),\n",
        "    ]\n",
        "\n",
        "    input_title_basics = [\n",
        "        ('tt0000001','short', 'name1', 'name1', 1, 1815, None, 300, 'Adventure'),\n",
        "        ('tt0000002','short', 'name2', 'name2', 0, 1816, None, 140, 'Drama'),\n",
        "        ('tt0000003','movie', 'name3', 'name3', 1, 1812, None, 110, 'Action,Drama,Thriller'),\n",
        "        ('tt0000004','short', 'name4', 'name4', 1, 1815, None, 300, 'Adventure'),\n",
        "        ('tt0000005','short', 'name5', 'name5', 0, 1811, None, 140, 'Drama'),\n",
        "        ('tt0000006','short', 'name6', 'name6', 1, 1812, None, 110, 'Action,Drama,Thriller'),\n",
        "        ('tt0000007','movie', 'name7', 'name7', 1, 1815, None, 300, 'Adventure'),\n",
        "        ('tt0000008','short', 'name8', 'name8', 0, 1811, None, 140, 'Drama'),\n",
        "        ('tt0000009','movie', 'name9', 'name9', 1, 1812, None, 110, 'Action,Drama,Thriller'),\n",
        "        ('tt0000010','short', 'name10', 'name10', 1, 1815, None, 300, 'Adventure'),\n",
        "    ]\n",
        "\n",
        "    expected_data_task8 = [\n",
        "        ('tt0000010', 'short', 'name10', 'name10', 'Adventure', 6.9),\n",
        "        ('tt0000001', 'short', 'name1', 'name1', 'Adventure', 5.9),\n",
        "        ('tt0000004', 'short', 'name4', 'name4', 'Adventure', 5.6),\n",
        "        ('tt0000007', 'movie', 'name7', 'name7', 'Adventure', 5.3),\n",
        "        ('tt0000002', 'short', 'name2', 'name2', 'Drama', 6.8),\n",
        "        ('tt0000003', 'movie', 'name3', 'name3', 'Drama', 5.7),\n",
        "        ('tt0000005', 'short', 'name5', 'name5', 'Drama', 5.5),\n",
        "        ('tt0000006', 'short', 'name6', 'name6', 'Drama', 5.4),\n",
        "        ('tt0000008', 'short', 'name8', 'name8', 'Drama', 5.2),\n",
        "        ('tt0000009', 'movie', 'name9', 'name9', 'Drama', 5.1),\n",
        "        ('tt0000003', 'movie', 'name3', 'name3', 'Action', 5.7),\n",
        "        ('tt0000006', 'short', 'name6', 'name6', 'Action', 5.4),\n",
        "        ('tt0000009', 'movie', 'name9', 'name9', 'Action', 5.1),\n",
        "        ('tt0000003', 'movie', 'name3', 'name3', 'Thriller', 5.7),\n",
        "        ('tt0000006', 'short', 'name6', 'name6', 'Thriller', 5.4),\n",
        "        ('tt0000009', 'movie', 'name9', 'name9', 'Thriller', 5.1),\n",
        "    ]\n",
        "\n",
        "    title_ratings_df = self.spark.createDataFrame(data = input_title_ratings, schema = schema_title_ratings)\n",
        "    title_basics_df = self.spark.createDataFrame(data = input_title_basics, schema = schema_title_basics)\n",
        "\n",
        "    col_id1 = 'Tconst'\n",
        "    col_id2 = 'Tconst2'\n",
        "    title_ratings_df = title_ratings_df.withColumnRenamed(col_id1, col_id2)\n",
        "\n",
        "    transformed_df = get_filter_df8(title_basics_df, title_ratings_df, col_id1, col_id2, self.spark)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task8, schema = schema_expected8)\n",
        "    # transformed_df.show()\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "\n",
        "unittest.main(argv=[''], defaultTest = \"TestFilters\", verbosity=2, exit=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_YDk43MXopo",
        "outputId": "c1f64a24-27e3-43f5-9ef4-9422b0562885"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_get_filter_df1 (__main__.TestFilters)\n",
            "Test case function for 1 task ... ok\n",
            "test_get_filter_df2 (__main__.TestFilters)\n",
            "Test case function for 2 task ... ok\n",
            "test_get_filter_df3 (__main__.TestFilters)\n",
            "Test case function for 3 task ... ok\n",
            "test_get_filter_df4 (__main__.TestFilters)\n",
            "Test case function for 4 task ... ok\n",
            "test_get_filter_df5 (__main__.TestFilters)\n",
            "Test case function for 5 task ... ok\n",
            "test_get_filter_df6 (__main__.TestFilters)\n",
            "Test case function for 6 task ... ok\n",
            "test_get_filter_df7 (__main__.TestFilters)\n",
            "Test case function for 7 task ... ok\n",
            "test_get_filter_df8 (__main__.TestFilters)\n",
            "Test case function for 8 task ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 8 tests in 5.960s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7fb15dbca990>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    }
  ]
}