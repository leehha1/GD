{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GD diploma project.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "8lzHv-A_S4qh",
        "ChGzMdC6S6sK",
        "PfXwENhIS7HR",
        "frAFbG0VS7-_",
        "e9RmZDb8S8Sk",
        "d-eWXTCsTPA_",
        "nI5Sfn_oTTCF",
        "1kcPTxdt-x_9"
      ]
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "id": "Kr4q1SpJHXU2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9feed182-29e0-48ec-9272-4a6a6ddfc560"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyspark"
      ],
      "metadata": {
        "id": "-sjJo3dcQNuL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b63823a5-c97c-4630-c207-313c7fb2b2d2"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.3.0)\n",
            "Requirement already satisfied: py4j==0.10.9.5 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.5)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark import SparkConf\n",
        "from pyspark.sql import SparkSession, Window\n",
        "import pyspark.sql.types as t\n",
        "import pyspark.sql.functions as f\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression, Ridge, RidgeCV, Lasso\n",
        "from datetime import datetime, timezone, timedelta\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "import unittest\n",
        "import pytest"
      ],
      "metadata": {
        "id": "HbeydiRcQPWd"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spark_session = (SparkSession.builder\n",
        "                             .master(\"local\") \n",
        "                             .appName(\"diploma project app\")\n",
        "                             .config(conf=SparkConf()) \n",
        "                             .getOrCreate())"
      ],
      "metadata": {
        "id": "MwBIHfm7QRMu"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print((filtered_title_basics_df.count(), len(filtered_title_basics_df.columns)))"
      ],
      "metadata": {
        "id": "hNtHXaN_65Ed"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_csv(path, work_schema, spark_session):\n",
        "  \"\"\"Read data from CSV\"\"\"\n",
        "  work_df = spark_session.read.csv(path,\n",
        "                                   sep=r'\\t',\n",
        "                                   header=True,\n",
        "                                   nullValue=r'\\N',\n",
        "                                   schema=work_schema)\n",
        "  return work_df"
      ],
      "metadata": {
        "id": "uK571c0uU2jZ"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def write_csv(df, path_to_save):\n",
        "  \"\"\"Write dafaframe to CSV as 1 file\"\"\"\n",
        "  df.coalesce(1).write.csv(path_to_save, header=True, mode=\"overwrite\")"
      ],
      "metadata": {
        "id": "PEiEM_J912G6"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Read all df"
      ],
      "metadata": {
        "id": "EQnEXzWWVIXm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read title.akas"
      ],
      "metadata": {
        "id": "iiIMYEaVVWv9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_title_akas = '/content/drive/MyDrive/GD/input_files/title.akas/data.tsv'\n",
        "schema_title_akas = t.StructType([t.StructField('TitleId', t.StringType(), True),\n",
        "                                t.StructField('Ordering', t.IntegerType(), True),\n",
        "                                t.StructField('Title', t.StringType(), True),\n",
        "                                t.StructField('Region', t.StringType(), True),\n",
        "                                t.StructField('Language', t.StringType(), True),\n",
        "                                t.StructField('Types', t.StringType(), True),\n",
        "                                t.StructField('Attributes', t.StringType(), True),\n",
        "                                t.StructField('IsOriginalTitle ',t.IntegerType(),True),\n",
        "])\n",
        "title_akas_df = read_csv(path_title_akas, schema_title_akas, spark_session)\n",
        "title_akas_df.show(40, truncate=False)"
      ],
      "metadata": {
        "id": "lNWj9hAlVNbw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93050e03-c611-45e4-823a-cd8f5611dc11"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+-------------------------+------+--------+-----------+--------------------------+----------------+\n",
            "|TitleId  |Ordering|Title                    |Region|Language|Types      |Attributes                |IsOriginalTitle |\n",
            "+---------+--------+-------------------------+------+--------+-----------+--------------------------+----------------+\n",
            "|tt0000001|1       |Карменсіта               |UA    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000001|2       |Carmencita               |DE    |null    |null       |literal title             |0               |\n",
            "|tt0000001|3       |Carmencita - spanyol tánc|HU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000001|4       |Καρμενσίτα               |GR    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000001|5       |Карменсита               |RU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000001|6       |Carmencita               |US    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000001|7       |Carmencita               |null  |null    |original   |null                      |1               |\n",
            "|tt0000001|8       |カルメンチータ           |JP    |ja      |imdbDisplay|null                      |0               |\n",
            "|tt0000002|1       |Le clown et ses chiens   |null  |null    |original   |null                      |1               |\n",
            "|tt0000002|2       |Le clown et ses chiens   |FR    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000002|3       |A bohóc és kutyái        |HU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000002|4       |Der Clown und seine Hunde|DE    |null    |null       |literal title             |0               |\n",
            "|tt0000002|5       |Clovnul si cainii sai    |RO    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000002|6       |Клоун и его собаки       |RU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000002|7       |The Clown and His Dogs   |US    |null    |null       |literal English title     |0               |\n",
            "|tt0000002|8       |道化師と犬               |JP    |ja      |imdbDisplay|null                      |0               |\n",
            "|tt0000003|1       |Sarmanul Pierrot         |RO    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000003|2       |Szegény Pierrot          |HU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000003|3       |哀れなピエロ             |JP    |ja      |imdbDisplay|null                      |0               |\n",
            "|tt0000003|4       |Бідний П'єро             |UA    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000003|5       |Бедный Пьеро             |RU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000003|6       |Pauvre Pierrot           |null  |null    |original   |null                      |1               |\n",
            "|tt0000003|7       |Poor Pierrot             |GB    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000003|8       |Pauvre Pierrot           |FR    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000003|9       |Armer Pierrot            |DE    |null    |null       |literal title             |0               |\n",
            "|tt0000004|1       |Un bon bock              |null  |null    |original   |null                      |1               |\n",
            "|tt0000004|2       |Un bon bock              |FR    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000004|3       |Ein gutes Glas Bier      |DE    |null    |null       |literal title             |0               |\n",
            "|tt0000004|4       |Un ţap de bere           |RO    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000004|5       |Полная кружка пива       |RU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000004|6       |一杯のビール             |JP    |ja      |imdbDisplay|null                      |0               |\n",
            "|tt0000004|7       |A Good Beer              |null  |null    |null       |null                      |0               |\n",
            "|tt0000004|8       |Egy jó pohár sör         |HU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000005|10      |Blacksmith Scene         |US    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000005|11      |Blacksmith Scene         |null  |null    |original   |null                      |1               |\n",
            "|tt0000005|12      |The Blacksmith's Forge   |GB    |null    |null       |informal alternative title|0               |\n",
            "|tt0000005|1       |Blacksmithing Scene      |US    |null    |alternative|null                      |0               |\n",
            "|tt0000005|2       |Ковальська сцена         |UA    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000005|3       |Сцена в кузне            |RU    |null    |imdbDisplay|null                      |0               |\n",
            "|tt0000005|4       |Blacksmith Scene         |CA    |en      |imdbDisplay|null                      |0               |\n",
            "+---------+--------+-------------------------+------+--------+-----------+--------------------------+----------------+\n",
            "only showing top 40 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read name.basics"
      ],
      "metadata": {
        "id": "YNBHyQFrWdpu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_name_basics = '/content/drive/MyDrive/GD/input_files/name.basics/data.tsv'\n",
        "schema_name_basics = t.StructType([t.StructField('TitleId', t.StringType(), True),\n",
        "                                  t.StructField('PrimaryName', t.StringType(), True),\n",
        "                                  t.StructField('BirthYear', t.IntegerType(), True),\n",
        "                                  t.StructField('DeathYear', t.IntegerType(), True),\n",
        "                                  t.StructField('PrimaryProfession', t.StringType(), True),\n",
        "                                  t.StructField('KnownForTitles', t.StringType(), True),\n",
        "])\n",
        "\n",
        "name_basics_df = read_csv(path_name_basics, schema_name_basics, spark_session)\n",
        "name_basics_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "qumE6PD-VNe_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9de00282-9808-4d00-94d6-feda27a28bca"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+---------+---------+-------------------------------------+---------------------------------------+\n",
            "|TitleId  |PrimaryName        |BirthYear|DeathYear|PrimaryProfession                    |KnownForTitles                         |\n",
            "+---------+-------------------+---------+---------+-------------------------------------+---------------------------------------+\n",
            "|nm0000001|Fred Astaire       |1899     |1987     |soundtrack,actor,miscellaneous       |tt0072308,tt0053137,tt0050419,tt0031983|\n",
            "|nm0000002|Lauren Bacall      |1924     |2014     |actress,soundtrack                   |tt0038355,tt0117057,tt0071877,tt0037382|\n",
            "|nm0000003|Brigitte Bardot    |1934     |null     |actress,soundtrack,music_department  |tt0057345,tt0049189,tt0054452,tt0056404|\n",
            "|nm0000004|John Belushi       |1949     |1982     |actor,soundtrack,writer              |tt0078723,tt0077975,tt0072562,tt0080455|\n",
            "|nm0000005|Ingmar Bergman     |1918     |2007     |writer,director,actor                |tt0083922,tt0050986,tt0060827,tt0050976|\n",
            "|nm0000006|Ingrid Bergman     |1915     |1982     |actress,soundtrack,producer          |tt0034583,tt0077711,tt0036855,tt0038109|\n",
            "|nm0000007|Humphrey Bogart    |1899     |1957     |actor,soundtrack,producer            |tt0043265,tt0037382,tt0034583,tt0042593|\n",
            "|nm0000008|Marlon Brando      |1924     |2004     |actor,soundtrack,director            |tt0068646,tt0078788,tt0070849,tt0047296|\n",
            "|nm0000009|Richard Burton     |1925     |1984     |actor,soundtrack,producer            |tt0059749,tt0087803,tt0061184,tt0057877|\n",
            "|nm0000010|James Cagney       |1899     |1986     |actor,soundtrack,director            |tt0042041,tt0035575,tt0055256,tt0029870|\n",
            "|nm0000011|Gary Cooper        |1901     |1961     |actor,soundtrack,producer            |tt0044706,tt0034167,tt0035896,tt0027996|\n",
            "|nm0000012|Bette Davis        |1908     |1989     |actress,soundtrack,make_up_department|tt0031210,tt0035140,tt0056687,tt0042192|\n",
            "|nm0000013|Doris Day          |1922     |2019     |soundtrack,actress,producer          |tt0049470,tt0053172,tt0048317,tt0045591|\n",
            "|nm0000014|Olivia de Havilland|1916     |2020     |actress,soundtrack                   |tt0031381,tt0041452,tt0040806,tt0029843|\n",
            "|nm0000015|James Dean         |1931     |1955     |actor,miscellaneous                  |tt0048028,tt0039123,tt0049261,tt0048545|\n",
            "|nm0000016|Georges Delerue    |1925     |1992     |composer,soundtrack,music_department |tt0096320,tt0069946,tt8847712,tt0091763|\n",
            "|nm0000017|Marlene Dietrich   |1901     |1992     |soundtrack,actress,music_department  |tt0052311,tt0055031,tt0051201,tt0021156|\n",
            "|nm0000018|Kirk Douglas       |1916     |2020     |actor,producer,soundtrack            |tt0080736,tt0043338,tt0054331,tt0049456|\n",
            "|nm0000019|Federico Fellini   |1920     |1993     |writer,director,assistant_director   |tt0071129,tt0053779,tt0050783,tt0056801|\n",
            "|nm0000020|Henry Fonda        |1905     |1982     |actor,producer,soundtrack            |tt0051207,tt0032551,tt0050083,tt0082846|\n",
            "+---------+-------------------+---------+---------+-------------------------------------+---------------------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read title.basics"
      ],
      "metadata": {
        "id": "pyyalQq9WjWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_title_basics = '/content/drive/MyDrive/GD/input_files/title.basics/data.tsv'\n",
        "  \n",
        "schema_title_basics = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                            t.StructField('TitleType', t.StringType(), True),\n",
        "                            t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                            t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                            t.StructField('IsAdult', t.IntegerType(), True),\n",
        "                            t.StructField('StartYear', t.IntegerType(), True),\n",
        "                            t.StructField('EndYear', t.IntegerType(), True),\n",
        "                            t.StructField('RuntimeMinutes', t.IntegerType(), True),\n",
        "                            t.StructField('Genres', t.StringType(), True),\n",
        "])\n",
        "\n",
        "title_basics_df = read_csv(path_title_basics, schema_title_basics, spark_session)\n",
        "title_basics_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "mpHy-sJgVNkp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5afbf36-65f2-46c9-c1e9-6f25c46052ae"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+-------------------------------------------+-------------------------------------------------+-------+---------+-------+--------------+------------------------+\n",
            "|Tconst   |TitleType|PrimaryTitle                               |OriginalTitle                                    |IsAdult|StartYear|EndYear|RuntimeMinutes|Genres                  |\n",
            "+---------+---------+-------------------------------------------+-------------------------------------------------+-------+---------+-------+--------------+------------------------+\n",
            "|tt0000001|short    |Carmencita                                 |Carmencita                                       |0      |1894     |null   |1             |Documentary,Short       |\n",
            "|tt0000002|short    |Le clown et ses chiens                     |Le clown et ses chiens                           |0      |1892     |null   |5             |Animation,Short         |\n",
            "|tt0000003|short    |Pauvre Pierrot                             |Pauvre Pierrot                                   |0      |1892     |null   |4             |Animation,Comedy,Romance|\n",
            "|tt0000004|short    |Un bon bock                                |Un bon bock                                      |0      |1892     |null   |12            |Animation,Short         |\n",
            "|tt0000005|short    |Blacksmith Scene                           |Blacksmith Scene                                 |0      |1893     |null   |1             |Comedy,Short            |\n",
            "|tt0000006|short    |Chinese Opium Den                          |Chinese Opium Den                                |0      |1894     |null   |1             |Short                   |\n",
            "|tt0000007|short    |Corbett and Courtney Before the Kinetograph|Corbett and Courtney Before the Kinetograph      |0      |1894     |null   |1             |Short,Sport             |\n",
            "|tt0000008|short    |Edison Kinetoscopic Record of a Sneeze     |Edison Kinetoscopic Record of a Sneeze           |0      |1894     |null   |1             |Documentary,Short       |\n",
            "|tt0000009|movie    |Miss Jerry                                 |Miss Jerry                                       |0      |1894     |null   |45            |Romance                 |\n",
            "|tt0000010|short    |Leaving the Factory                        |La sortie de l'usine Lumière à Lyon              |0      |1895     |null   |1             |Documentary,Short       |\n",
            "|tt0000011|short    |Akrobatisches Potpourri                    |Akrobatisches Potpourri                          |0      |1895     |null   |1             |Documentary,Short       |\n",
            "|tt0000012|short    |The Arrival of a Train                     |L'arrivée d'un train à La Ciotat                 |0      |1896     |null   |1             |Documentary,Short       |\n",
            "|tt0000013|short    |The Photographical Congress Arrives in Lyon|Le débarquement du congrès de photographie à Lyon|0      |1895     |null   |1             |Documentary,Short       |\n",
            "|tt0000014|short    |The Waterer Watered                        |L'arroseur arrosé                                |0      |1895     |null   |1             |Comedy,Short            |\n",
            "|tt0000015|short    |Autour d'une cabine                        |Autour d'une cabine                              |0      |1894     |null   |2             |Animation,Short         |\n",
            "|tt0000016|short    |Boat Leaving the Port                      |Barque sortant du port                           |0      |1895     |null   |1             |Documentary,Short       |\n",
            "|tt0000017|short    |Italienischer Bauerntanz                   |Italienischer Bauerntanz                         |0      |1895     |null   |1             |Documentary,Short       |\n",
            "|tt0000018|short    |Das boxende Känguruh                       |Das boxende Känguruh                             |0      |1895     |null   |1             |Short                   |\n",
            "|tt0000019|short    |The Clown Barber                           |The Clown Barber                                 |0      |1898     |null   |null          |Comedy,Short            |\n",
            "|tt0000020|short    |The Derby 1895                             |The Derby 1895                                   |0      |1895     |null   |1             |Documentary,Short,Sport |\n",
            "+---------+---------+-------------------------------------------+-------------------------------------------------+-------+---------+-------+--------------+------------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read title.principals"
      ],
      "metadata": {
        "id": "tmrEPGAcXRNl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_title_principals = '/content/drive/MyDrive/GD/input_files/title.principals/data.tsv'\n",
        "  \n",
        "schema_title_principals = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                        t.StructField('Ordering', t.IntegerType(), True),\n",
        "                                        t.StructField('Nconst', t.StringType(), True),\n",
        "                                        t.StructField('Category', t.StringType(), True),\n",
        "                                        t.StructField('Job', t.StringType(), True),\n",
        "                                        t.StructField('Characters', t.StringType(), True),\n",
        "                                      ])\n",
        "\n",
        "title_principals_df = read_csv(path_title_principals, schema_title_principals, spark_session)\n",
        "title_principals_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "U-GdaRh2VNnC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "957789d2-a771-4897-a0c9-288e232b58e2"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+---------+---------------+-----------------------+--------------+\n",
            "|Tconst   |Ordering|Nconst   |Category       |Job                    |Characters    |\n",
            "+---------+--------+---------+---------------+-----------------------+--------------+\n",
            "|tt0000001|1       |nm1588970|self           |null                   |[\"Self\"]      |\n",
            "|tt0000001|2       |nm0005690|director       |null                   |null          |\n",
            "|tt0000001|3       |nm0374658|cinematographer|director of photography|null          |\n",
            "|tt0000002|1       |nm0721526|director       |null                   |null          |\n",
            "|tt0000002|2       |nm1335271|composer       |null                   |null          |\n",
            "|tt0000003|1       |nm0721526|director       |null                   |null          |\n",
            "|tt0000003|2       |nm1770680|producer       |producer               |null          |\n",
            "|tt0000003|3       |nm1335271|composer       |null                   |null          |\n",
            "|tt0000003|4       |nm5442200|editor         |null                   |null          |\n",
            "|tt0000004|1       |nm0721526|director       |null                   |null          |\n",
            "|tt0000004|2       |nm1335271|composer       |null                   |null          |\n",
            "|tt0000005|1       |nm0443482|actor          |null                   |[\"Blacksmith\"]|\n",
            "|tt0000005|2       |nm0653042|actor          |null                   |[\"Assistant\"] |\n",
            "|tt0000005|3       |nm0005690|director       |null                   |null          |\n",
            "|tt0000005|4       |nm0249379|producer       |producer               |null          |\n",
            "|tt0000006|1       |nm0005690|director       |null                   |null          |\n",
            "|tt0000007|1       |nm0179163|actor          |null                   |null          |\n",
            "|tt0000007|2       |nm0183947|actor          |null                   |null          |\n",
            "|tt0000007|3       |nm0005690|director       |null                   |null          |\n",
            "|tt0000007|4       |nm0374658|director       |null                   |null          |\n",
            "+---------+--------+---------+---------------+-----------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read title.episode"
      ],
      "metadata": {
        "id": "3R5vG_hiXUzl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_title_episode = '/content/drive/MyDrive/GD/input_files/title.episode/data.tsv'\n",
        "\n",
        "schema_title_episode = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                    t.StructField('ParentTconst', t.StringType(), True),\n",
        "                                    t.StructField('SeasonNumber', t.IntegerType(), True),\n",
        "                                    t.StructField('EpisodeNumber ', t.IntegerType(), True),\n",
        "                                  ])\n",
        "\n",
        "\n",
        "title_episode_df = read_csv(path_title_episode, schema_title_episode, spark_session)\n",
        "title_episode_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "pGacPN1KVNrq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ab07ff5-7095-416a-fe4c-baa6601e6ddb"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------+------------+--------------+\n",
            "|Tconst   |ParentTconst|SeasonNumber|EpisodeNumber |\n",
            "+---------+------------+------------+--------------+\n",
            "|tt0020666|tt15180956  |1           |2             |\n",
            "|tt0020829|tt15180956  |1           |1             |\n",
            "|tt0021166|tt15180956  |1           |3             |\n",
            "|tt0021612|tt15180956  |2           |2             |\n",
            "|tt0021655|tt15180956  |2           |5             |\n",
            "|tt0021663|tt15180956  |2           |6             |\n",
            "|tt0021664|tt15180956  |2           |4             |\n",
            "|tt0021701|tt15180956  |2           |1             |\n",
            "|tt0021802|tt15180956  |2           |11            |\n",
            "|tt0022009|tt15180956  |2           |10            |\n",
            "|tt0022031|tt15180956  |2           |8             |\n",
            "|tt0022127|tt15180956  |2           |9             |\n",
            "|tt0022152|tt15180956  |2           |7             |\n",
            "|tt0022385|tt15180956  |2           |3             |\n",
            "|tt0022604|tt15180956  |3           |8             |\n",
            "|tt0022610|tt15180956  |3           |10            |\n",
            "|tt0022631|tt15180956  |3           |1             |\n",
            "|tt0022666|tt15180956  |3           |11            |\n",
            "|tt0022667|tt15180956  |3           |17            |\n",
            "|tt0022668|tt15180956  |3           |15            |\n",
            "+---------+------------+------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read title.crew"
      ],
      "metadata": {
        "id": "OVFBTwPMYpvv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_title_crew = '/content/drive/MyDrive/GD/input_files/title.crew/data.tsv'\n",
        "\n",
        "schema_title_crew = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                    t.StructField('Directors', t.StringType(), True),\n",
        "                                    t.StructField('Writers ', t.StringType(), True),\n",
        "                                  ])\n",
        "\n",
        "\n",
        "title_crew_df = read_csv(path_title_crew, schema_title_crew, spark_session)\n",
        "title_crew_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "rIpH8dZ3VN3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22399969-4362-444d-b022-bd330c735668"
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------------+---------+\n",
            "|Tconst   |Directors          |Writers  |\n",
            "+---------+-------------------+---------+\n",
            "|tt0000001|nm0005690          |null     |\n",
            "|tt0000002|nm0721526          |null     |\n",
            "|tt0000003|nm0721526          |null     |\n",
            "|tt0000004|nm0721526          |null     |\n",
            "|tt0000005|nm0005690          |null     |\n",
            "|tt0000006|nm0005690          |null     |\n",
            "|tt0000007|nm0005690,nm0374658|null     |\n",
            "|tt0000008|nm0005690          |null     |\n",
            "|tt0000009|nm0085156          |nm0085156|\n",
            "|tt0000010|nm0525910          |null     |\n",
            "|tt0000011|nm0804434          |null     |\n",
            "|tt0000012|nm0525910,nm0525908|null     |\n",
            "|tt0000013|nm0525910          |null     |\n",
            "|tt0000014|nm0525910          |null     |\n",
            "|tt0000015|nm0721526          |null     |\n",
            "|tt0000016|nm0525910          |null     |\n",
            "|tt0000017|nm1587194,nm0804434|null     |\n",
            "|tt0000018|nm0804434          |null     |\n",
            "|tt0000019|nm0932055          |null     |\n",
            "|tt0000020|nm0010291          |null     |\n",
            "+---------+-------------------+---------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Read title.ratings"
      ],
      "metadata": {
        "id": "UFcUZdGCYqaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_title_ratings = '/content/drive/MyDrive/GD/input_files/title.ratings/data.tsv'\n",
        "\n",
        "schema_title_ratings = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                     t.StructField('AverageRating', t.FloatType(), True),\n",
        "                                     t.StructField('NumVotes', t.IntegerType(), True),\n",
        "                                   ])\n",
        "\n",
        "\n",
        "title_ratings_df = read_csv(path_title_ratings, schema_title_ratings, spark_session)\n",
        "title_ratings_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "7sTC8Bt0VPR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7b4bb77c-c133-423b-fc5e-db836cda473b"
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+-------------+--------+\n",
            "|Tconst   |AverageRating|NumVotes|\n",
            "+---------+-------------+--------+\n",
            "|tt0000001|5.7          |1899    |\n",
            "|tt0000002|5.9          |254     |\n",
            "|tt0000003|6.5          |1692    |\n",
            "|tt0000004|5.7          |166     |\n",
            "|tt0000005|6.2          |2509    |\n",
            "|tt0000006|5.2          |172     |\n",
            "|tt0000007|5.4          |784     |\n",
            "|tt0000008|5.4          |2037    |\n",
            "|tt0000009|5.3          |197     |\n",
            "|tt0000010|6.9          |6863    |\n",
            "|tt0000011|5.3          |352     |\n",
            "|tt0000012|7.4          |11768   |\n",
            "|tt0000013|5.7          |1817    |\n",
            "|tt0000014|7.1          |5276    |\n",
            "|tt0000015|6.2          |1015    |\n",
            "|tt0000016|5.9          |1421    |\n",
            "|tt0000017|4.6          |310     |\n",
            "|tt0000018|5.3          |569     |\n",
            "|tt0000019|5.2          |31      |\n",
            "|tt0000020|4.8          |339     |\n",
            "+---------+-------------+--------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Get all titles of series/movies etc. that are available in Ukrainian."
      ],
      "metadata": {
        "id": "8lzHv-A_S4qh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df1(df, column, value,target_column):\n",
        "  \"\"\"Get all titles of series/movies etc. that are available in Ukrainian.\"\"\"\n",
        "  \n",
        "  df = df.filter(f.col(column) == value)\n",
        "  return df.na.drop(subset=[target_column])\n",
        "\n",
        "col = \"Region\"\n",
        "value = \"UA\"\n",
        "target_column = \"Title\"\n",
        "\n",
        "filtered_title_akas_df = get_filter_df1(title_akas_df, col, value,target_column)\n",
        "filtered_title_akas_df.show()"
      ],
      "metadata": {
        "id": "6q-ZkV0EB66Q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e71c71af-95c2-4d77-d683-928269ebd871"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+--------+--------------------+------+--------+-----------+----------+----------------+\n",
            "|  TitleId|Ordering|               Title|Region|Language|      Types|Attributes|IsOriginalTitle |\n",
            "+---------+--------+--------------------+------+--------+-----------+----------+----------------+\n",
            "|tt0000001|       1|          Карменсіта|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000003|       4|        Бідний П'єро|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000005|       2|    Ковальська сцена|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000008|       9|   Чхання Фреда Отта|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000010|      10|Вихід робітників ...|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000012|      26|Прибуття потяга н...|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000013|      13|Прибуття делегаті...|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000014|      19| Политий поливальник|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000015|       6|     Навколо кабінки|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000022|       5|              Ковалі|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000023|       2|     Морське купання|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000026|      12|      Партія в карти|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000027|       1|Площа Кордельє в ...|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000028|       4|Виловлювання черв...|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000029|      17|  Сніданок немовляти|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000031|       8|Стрибок через бре...|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000033|      11|       Вольтижування|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000041|       5|        Гра в сніжки|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000070|      16|    Зруйнування муру|    UA|    null|imdbDisplay|      null|               0|\n",
            "|tt0000091|       5|       Замок диявола|    UA|    null|imdbDisplay|      null|               0|\n",
            "+---------+--------+--------------------+------+--------+-----------+----------+----------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Get the list of people’s names, who were born in the 19th century."
      ],
      "metadata": {
        "id": "ChGzMdC6S6sK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df2(df, column, values, target_column):\n",
        "  \"\"\"Get the list of people’s names, who were born in the 19th century.\"\"\"\n",
        "  \n",
        "  df = df.filter((f.col(column) >= values[0]) & (f.col(column) <= values[1]))\n",
        "  return df.na.drop(subset=[target_column])\n",
        "\n",
        "col = \"BirthYear\"\n",
        "values = [1801, 1900] # 19th century.\n",
        "target_column = 'PrimaryName'\n",
        "\n",
        "filtered_name_basics_df = get_filter_df2(name_basics_df, col, values, target_column)\n",
        "filtered_name_basics_df.show()"
      ],
      "metadata": {
        "id": "3FvXQtPeRtmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c322565-e7a9-49de-f669-8ed277b8fcc7"
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+------------------+---------+---------+--------------------+--------------------+\n",
            "|  TitleId|       PrimaryName|BirthYear|DeathYear|   PrimaryProfession|      KnownForTitles|\n",
            "+---------+------------------+---------+---------+--------------------+--------------------+\n",
            "|nm0000001|      Fred Astaire|     1899|     1987|soundtrack,actor,...|tt0072308,tt00531...|\n",
            "|nm0000007|   Humphrey Bogart|     1899|     1957|actor,soundtrack,...|tt0043265,tt00373...|\n",
            "|nm0000010|      James Cagney|     1899|     1986|actor,soundtrack,...|tt0042041,tt00355...|\n",
            "|nm0000033|  Alfred Hitchcock|     1899|     1980|director,producer...|tt0053125,tt00542...|\n",
            "|nm0000036|     Buster Keaton|     1895|     1966|actor,writer,dire...|tt0016332,tt00153...|\n",
            "|nm0000050|      Groucho Marx|     1890|     1977|soundtrack,actor,...|tt0028772,tt00197...|\n",
            "|nm0000055|     Alfred Newman|     1900|     1970|music_department,...|tt0065377,tt00560...|\n",
            "|nm0000064|Edward G. Robinson|     1893|     1973|actor,soundtrack,...|tt0040506,tt00389...|\n",
            "|nm0000068|    Randolph Scott|     1898|     1987|actor,producer,so...|tt0029284,tt00564...|\n",
            "|nm0000070|       Max Steiner|     1888|     1971|music_department,...|tt0031381,tt00345...|\n",
            "|nm0000075|     Spencer Tracy|     1900|     1967|    actor,soundtrack|tt0047849,tt00539...|\n",
            "|nm0000082|      Victor Young|     1900|     1956|music_department,...|tt0048960,tt01190...|\n",
            "|nm0000122|   Charles Chaplin|     1889|     1977|writer,soundtrack...|tt0018773,tt00448...|\n",
            "|nm0000252|      Robert Ellis|     1892|     1974|actor,director,wr...|tt0030778,tt00325...|\n",
            "|nm0000253|      Robert Ellis|     1888|     1935|art_director,misc...|tt0014515,tt00264...|\n",
            "|nm0000311|       Annie Rosar|     1888|     1963|  actress,soundtrack|tt0052996,tt00343...|\n",
            "|nm0000320|       Luis Buñuel|     1900|     1983|writer,director,a...|tt0068361,tt00567...|\n",
            "|nm0000406|         John Ford|     1894|     1973|director,producer...|tt0045061,tt00319...|\n",
            "|nm0000428|     D.W. Griffith|     1875|     1948|director,writer,p...|tt0006864,tt00104...|\n",
            "|nm0000472|     Boris Karloff|     1887|     1969|    actor,soundtrack|tt0023194,tt00248...|\n",
            "+---------+------------------+---------+---------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Get titles of all movies that last more than 2 hours."
      ],
      "metadata": {
        "id": "PfXwENhIS7HR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df3(df, column1, value1, column2, value2, target_column):\n",
        "  \"\"\"Get titles of all movies that last more than 2 hours.\"\"\"\n",
        "\n",
        "  df = df.filter((f.col(column1) > value1) & (f.col(column2).isin(value2)))\n",
        "  return df.na.drop(subset=target_column)\n",
        "\n",
        "col1 = \"RuntimeMinutes\"\n",
        "value1 = 120 # 2 hours in minutes\n",
        "col2 = \"TitleType\"\n",
        "value2 = ['movie', 'tvMovie']\n",
        "target_column = ['PrimaryTitle', 'OriginalTitle']\n",
        "\n",
        "filtered_title_basics_df = get_filter_df3(title_basics_df, col1, value1, col2, value2, target_column)\n",
        "filtered_title_basics_df.show(truncate=False)"
      ],
      "metadata": {
        "id": "lunU9HHnT8_K",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dda5da05-159b-413a-baa9-15ddbd831a6d"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+---------------------------------------+---------------------------------------+-------+---------+-------+--------------+-----------------------+\n",
            "|Tconst   |TitleType|PrimaryTitle                           |OriginalTitle                          |IsAdult|StartYear|EndYear|RuntimeMinutes|Genres                 |\n",
            "+---------+---------+---------------------------------------+---------------------------------------+-------+---------+-------+--------------+-----------------------+\n",
            "|tt0002574|movie    |What Happened to Mary                  |What Happened to Mary                  |0      |1912     |null   |150           |Action,Drama,Thriller  |\n",
            "|tt0002605|movie    |The Adventures of Kathlyn              |The Adventures of Kathlyn              |0      |1913     |null   |300           |Adventure              |\n",
            "|tt0002646|movie    |Atlantis                               |Atlantis                               |0      |1913     |null   |121           |Drama                  |\n",
            "|tt0002898|movie    |Germinal; or, The Toll of Labor        |Germinal                               |0      |1913     |null   |150           |Drama                  |\n",
            "|tt0003159|movie    |Les Misérables, Part 2: Fantine        |Les misérables - Époque 2: Fantine     |0      |1913     |null   |300           |Drama                  |\n",
            "|tt0003596|movie    |The Active Life of Dolly of the Dailies|The Active Life of Dolly of the Dailies|0      |1914     |null   |170           |Drama                  |\n",
            "|tt0003675|movie    |The Beloved Adventurer                 |The Beloved Adventurer                 |0      |1914     |null   |450           |Adventure              |\n",
            "|tt0003740|movie    |Cabiria                                |Cabiria                                |0      |1914     |null   |148           |Adventure,Drama,History|\n",
            "|tt0003883|movie    |L'enfant de Paris                      |L'enfant de Paris                      |0      |1913     |null   |124           |Crime,Drama            |\n",
            "|tt0003897|movie    |The Exploits of Elaine                 |The Exploits of Elaine                 |0      |1914     |null   |220           |Action                 |\n",
            "|tt0004052|movie    |The Hazards of Helen                   |The Hazards of Helen                   |0      |1914     |null   |1428          |Action                 |\n",
            "|tt0004272|movie    |Lucille Love: The Girl of Mystery      |Lucille Love: The Girl of Mystery      |0      |1914     |null   |300           |Action                 |\n",
            "|tt0004313|movie    |The Master Key                         |The Master Key                         |0      |1914     |null   |310           |Action,Adventure,Drama |\n",
            "|tt0004465|movie    |The Perils of Pauline                  |The Perils of Pauline                  |0      |1914     |null   |199           |Action,Adventure,Drama |\n",
            "|tt0004483|movie    |The Port of Missing Men                |The Port of Missing Men                |0      |1914     |null   |139           |Drama                  |\n",
            "|tt0004594|movie    |El signo de la tribu                   |El signo de la tribu                   |0      |1914     |null   |219           |null                   |\n",
            "|tt0004727|movie    |The Trey o' Hearts                     |The Trey o' Hearts                     |0      |1914     |null   |310           |Adventure              |\n",
            "|tt0004972|movie    |The Birth of a Nation                  |The Birth of a Nation                  |0      |1915     |null   |195           |Drama,History,War      |\n",
            "|tt0004974|movie    |The Black Box                          |The Black Box                          |0      |1915     |null   |195           |Drama,Sci-Fi           |\n",
            "|tt0005005|movie    |The Broken Coin                        |The Broken Coin                        |0      |1915     |null   |440           |Adventure,Mystery      |\n",
            "+---------+---------+---------------------------------------+---------------------------------------+-------+---------+-------+--------------+-----------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Get names of people, corresponding movies/series and characters they played in those films. "
      ],
      "metadata": {
        "id": "CvaQCTDWS7kJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df4(name_basics_df, title_basics_df, title_principals_df, \n",
        "                   col_id, col_id_name, col_name, col_film, col_char):\n",
        "  \"\"\"Get names of people, corresponding movies/series and characters they played in those films.\"\"\"\n",
        "\n",
        "  new_df1 = name_basics_df.select([col_id_name, col_name])\n",
        "  new_df2 = title_basics_df.select([col_id, col_film[0], col_film[1]])\n",
        "  new_df3 = title_principals_df.select([col_id, col_char])\n",
        "  \n",
        "  new_df1 = new_df1.select([f.split(f.col(col_id_name),\",\").alias(col_id_name), col_name])\n",
        "  new_df1 = new_df1.select([f.explode(new_df1[col_id_name]).alias(col_id_name), new_df1[col_name]])\n",
        "  new_df3 = new_df3.withColumn( col_char, f.translate(f.col(col_char), '[\"]', \"\"))\n",
        "  # return new_df3\n",
        "\n",
        "  df4 = new_df1.join(new_df2, new_df1[col_id_name] ==  new_df2[col_id], \"inner\")\n",
        "  df4 = df4.join(new_df3, df4[col_id] ==  new_df3[col_id], \"inner\").drop(col_id)\n",
        "  df4 = df4.withColumnRenamed(col_id_name, col_id)\n",
        "  \n",
        "  return df4\n",
        "\n",
        "col_id = \"Tconst\"\n",
        "col_id_name = 'KnownForTitles'\n",
        "col_name = \"PrimaryName\"\n",
        "col_film = ['PrimaryTitle', 'OriginalTitle']\n",
        "col_char = 'Characters'\n",
        "\n",
        "\n",
        "result_df4  = get_filter_df4(name_basics_df, title_basics_df, title_principals_df, \n",
        "                        col_id, col_id_name, col_name, col_film, col_char)\n",
        "result_df4.show(truncate=False)"
      ],
      "metadata": {
        "id": "wWx4BWxx7m9E",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3008b33-46ad-49f0-f3e7-d9f3cab800ca"
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+----------------+-------------------------------+-------------------------------+--------------+\n",
            "|Tconst   |PrimaryName     |PrimaryTitle                   |OriginalTitle                  |Characters    |\n",
            "+---------+----------------+-------------------------------+-------------------------------+--------------+\n",
            "|tt0000174|Jan Krízenecký  |Výstavní párkar a lepic plakátù|Výstavní párkar a lepic plakátù|Sausage Vendor|\n",
            "|tt0000174|Jan Krízenecký  |Výstavní párkar a lepic plakátù|Výstavní párkar a lepic plakátù|Sticker       |\n",
            "|tt0000174|Jan Krízenecký  |Výstavní párkar a lepic plakátù|Výstavní párkar a lepic plakátù|null          |\n",
            "|tt0000174|Ferdinand Gýra  |Výstavní párkar a lepic plakátù|Výstavní párkar a lepic plakátù|Sausage Vendor|\n",
            "|tt0000174|Ferdinand Gýra  |Výstavní párkar a lepic plakátù|Výstavní párkar a lepic plakátù|Sticker       |\n",
            "|tt0000174|Ferdinand Gýra  |Výstavní párkar a lepic plakátù|Výstavní párkar a lepic plakátù|null          |\n",
            "|tt0000305|Valentine Brouat|L'Habanera                     |L'Habanera                     |null          |\n",
            "|tt0000305|Valentine Brouat|L'Habanera                     |L'Habanera                     |null          |\n",
            "|tt0000451|Laura Bayley    |Mary Jane's Mishap             |Mary Jane's Mishap             |Mary Jane     |\n",
            "|tt0000451|Laura Bayley    |Mary Jane's Mishap             |Mary Jane's Mishap             |null          |\n",
            "|tt0000621|Gertie Potter   |That Fatal Sneeze              |That Fatal Sneeze              |Uncle         |\n",
            "|tt0000621|Gertie Potter   |That Fatal Sneeze              |That Fatal Sneeze              |Nephew        |\n",
            "|tt0000621|Gertie Potter   |That Fatal Sneeze              |That Fatal Sneeze              |null          |\n",
            "|tt0000621|Gertie Potter   |That Fatal Sneeze              |That Fatal Sneeze              |null          |\n",
            "|tt0000621|Thurston Harris |That Fatal Sneeze              |That Fatal Sneeze              |Uncle         |\n",
            "|tt0000621|Thurston Harris |That Fatal Sneeze              |That Fatal Sneeze              |Nephew        |\n",
            "|tt0000621|Thurston Harris |That Fatal Sneeze              |That Fatal Sneeze              |null          |\n",
            "|tt0000621|Thurston Harris |That Fatal Sneeze              |That Fatal Sneeze              |null          |\n",
            "|tt0000862|Schiøler Linck  |Faldgruben                     |Faldgruben                     |Doktor        |\n",
            "|tt0000862|Schiøler Linck  |Faldgruben                     |Faldgruben                     |Charles       |\n",
            "+---------+----------------+-------------------------------+-------------------------------+--------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Get information about how many adult movies/series etc. there are per region. Get the top 100 of them from the region with the biggest count to the region with the smallest one."
      ],
      "metadata": {
        "id": "frAFbG0VS7-_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df5(title_basics_df, title_akas_df, col1, col2, col_id1, col_id2):\n",
        "  \"\"\"\n",
        "  Get information about how many adult movies/series etc. there are per region. \n",
        "  Get the top 100 of them from the region with the biggest count to the region with the smallest one.\n",
        "  \"\"\"\n",
        "\n",
        "  joined_df = title_basics_df.join(title_akas_df, title_basics_df[col_id1] ==  title_akas_df[col_id2], \"inner\")\n",
        "  joined_df = joined_df.filter(f.col(col1) == 1)\n",
        "  joined_df = joined_df.na.drop(subset=[col1, col2])\n",
        "  return joined_df.groupBy(col2).count().orderBy('count', ascending=False).limit(100)\n",
        "\n",
        "col1 = 'IsAdult'\n",
        "col2 = 'Region'\n",
        "col_id1 = 'Tconst'\n",
        "col_id2 = 'TitleId'\n",
        "\n",
        "result_df5 = get_filter_df5(title_basics_df, title_akas_df, col1, col2, col_id1, col_id2)\n",
        "\n",
        "result_df5.show()"
      ],
      "metadata": {
        "id": "zoYPCHSiS6LM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4832336-678e-4e68-e5aa-5374e6643673"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+-----+\n",
            "|Region|count|\n",
            "+------+-----+\n",
            "|    US|93168|\n",
            "|    JP|21073|\n",
            "|    DE|12446|\n",
            "|    FR| 8035|\n",
            "|    ES| 6244|\n",
            "|    IT| 5944|\n",
            "|    CA| 5381|\n",
            "|    GB| 4455|\n",
            "|    VE| 3685|\n",
            "|    PT| 3508|\n",
            "|    IN| 3170|\n",
            "|   XWW| 2693|\n",
            "|    NL| 2025|\n",
            "|    BR| 1939|\n",
            "|    CZ| 1561|\n",
            "|    SE| 1381|\n",
            "|   XWG| 1170|\n",
            "|    HU|  866|\n",
            "|    GR|  860|\n",
            "|    DK|  808|\n",
            "+------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Get information about how many episodes in each TV Series. Get the top 50 of them starting from the TV Series with the biggest quantity of episodes."
      ],
      "metadata": {
        "id": "e9RmZDb8S8Sk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df6(title_episode_df, col_id, col_count):\n",
        "  \"\"\"\n",
        "  Get information about how many episodes in each TV Series. \n",
        "  Get the top 50 of them starting from the TV Series with the biggest quantity of episodes.\n",
        "  \"\"\"\n",
        "\n",
        "  new_df = title_episode_df.select([col_id, col_count])\n",
        "  return new_df.groupBy(col_id).count().orderBy('count', ascending=False).limit(50)\n",
        "\n",
        "col_id = \"ParentTconst\"\n",
        "col_count = \"Tconst\"\n",
        "\n",
        "result_df6  = get_filter_df6(title_episode_df, col_id, col_count)\n",
        "result_df6.show(truncate=False)"
      ],
      "metadata": {
        "id": "al7lG7SKPq8h",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bac055b-9d27-4296-d861-d829882eb39f"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------------+-----+\n",
            "|ParentTconst|count|\n",
            "+------------+-----+\n",
            "|tt12164062  |18045|\n",
            "|tt0058796   |14559|\n",
            "|tt0069658   |12532|\n",
            "|tt0988827   |10674|\n",
            "|tt0053494   |10505|\n",
            "|tt0344642   |10015|\n",
            "|tt0270116   |9885 |\n",
            "|tt0055708   |9807 |\n",
            "|tt0363402   |9580 |\n",
            "|tt1985601   |9502 |\n",
            "|tt0068120   |9320 |\n",
            "|tt0380100   |9220 |\n",
            "|tt0088580   |9199 |\n",
            "|tt0283794   |9010 |\n",
            "|tt0434733   |9004 |\n",
            "|tt0092325   |8775 |\n",
            "|tt0159881   |8632 |\n",
            "|tt0283767   |8456 |\n",
            "|tt0068069   |8368 |\n",
            "|tt0439979   |8286 |\n",
            "+------------+-----+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.\tGet 10 titles of the most popular movies/series etc. by each decade. "
      ],
      "metadata": {
        "id": "d-eWXTCsTPA_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df7(title_basics_df, title_ratings_df, col_id1, col_id2, spark_session):\n",
        "  \"\"\"Get 10 titles of the most popular movies/series etc. by each decade.\"\"\"\n",
        "\n",
        "  schema_result_df7 = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                    t.StructField('TitleType', t.StringType(), True),\n",
        "                                    t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                    t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                    t.StructField('StartYear', t.IntegerType(), True),\n",
        "                                    t.StructField('Decade', t.IntegerType(), True),\n",
        "                                    t.StructField('AverageRating', t.FloatType(), True),\n",
        "                                  ])\n",
        "  data_df7 = []\n",
        "  df7 = spark_session.createDataFrame(data = data_df7, schema = schema_result_df7)\n",
        "\n",
        "  result_df7 = title_basics_df.join(title_ratings_df, title_basics_df[col_id1] ==  title_ratings_df[col_id2], \"inner\").drop(col_id2)\n",
        "  result_df7 = result_df7.na.drop(subset=['PrimaryTitle', 'OriginalTitle', 'StartYear', 'AverageRating'])\n",
        "  result_df7 = result_df7.withColumn('Decade', ((f.col('StartYear')-1) / 10).cast('int'))\n",
        "  list_decades = result_df7.toPandas()['Decade'].unique().tolist()\n",
        "\n",
        "  for dec in list_decades:\n",
        "    df7 = (df7.union(result_df7.select([col_id1, 'TitleType', 'PrimaryTitle', 'OriginalTitle', 'StartYear', 'Decade', 'AverageRating'])\n",
        "                               .filter(f.col('Decade') == dec)\n",
        "                               .orderBy('AverageRating', ascending=False).limit(10)))\n",
        "  return df7\n",
        "\n",
        "col_id1 = 'Tconst'\n",
        "col_id2 = 'Tconst2'\n",
        "title_ratings_df = title_ratings_df.withColumnRenamed(col_id1, col_id2)\n",
        "\n",
        "result_df7 = get_filter_df7(title_basics_df, title_ratings_df, col_id1, col_id2, spark_session)\n",
        "result_df7.show(truncate=False)"
      ],
      "metadata": {
        "id": "qT4GP0ezS6Fx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "66868399-7b9d-4865-c6b7-d5ac1901d964"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+---------+------+-------------+\n",
            "|Tconst   |TitleType|PrimaryTitle                                                                                                                                  |OriginalTitle                                                                                                                                 |StartYear|Decade|AverageRating|\n",
            "+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+---------+------+-------------+\n",
            "|tt0270202|short    |Another Picture Showing Demonstration of a Pneumatic Shell Riveter                                                                            |Another Picture Showing Demonstration of a Pneumatic Shell Riveter                                                                            |1900     |189   |8.4          |\n",
            "|tt0302466|short    |Demonstrating the Action of the Brown Hoisting and Conveying Machine in Unloading a Schooner of Iron Ore, and Loading the Material on the Cars|Demonstrating the Action of the Brown Hoisting and Conveying Machine in Unloading a Schooner of Iron Ore, and Loading the Material on the Cars|1900     |189   |8.1          |\n",
            "|tt0288497|short    |Demonstrating the Operation of the Harrington Rail Bonding System on the Line of the Coney Island and Brooklyn Railroad Co.                   |Demonstrating the Operation of the Harrington Rail Bonding System on the Line of the Coney Island and Brooklyn Railroad Co.                   |1900     |189   |7.9          |\n",
            "|tt0135696|short    |Four Heads Are Better Than One                                                                                                                |Un homme de têtes                                                                                                                             |1898     |189   |7.6          |\n",
            "|tt0000060|short    |Dancing Darkies                                                                                                                               |Dancing Darkies                                                                                                                               |1896     |189   |7.5          |\n",
            "|tt0000211|short    |The Astronomer's Dream; or, the Man in the Moon                                                                                               |La lune à un mètre                                                                                                                            |1898     |189   |7.5          |\n",
            "|tt2184114|short    |The Telephone No. 2                                                                                                                           |The Telephone No. 2                                                                                                                           |1898     |189   |7.4          |\n",
            "|tt1959451|short    |Let 'Em All Come                                                                                                                              |Let 'Em All Come                                                                                                                              |1899     |189   |7.4          |\n",
            "|tt0000012|short    |The Arrival of a Train                                                                                                                        |L'arrivée d'un train à La Ciotat                                                                                                              |1896     |189   |7.4          |\n",
            "|tt2374973|short    |Edinburgh                                                                                                                                     |Edinburgh                                                                                                                                     |1898     |189   |7.4          |\n",
            "|tt0210346|short    |Theodora                                                                                                                                      |Teodora imperatrice di Bisanzio                                                                                                               |1909     |190   |9.4          |\n",
            "|tt0418716|short    |Halloween                                                                                                                                     |Halloween                                                                                                                                     |1905     |190   |8.9          |\n",
            "|tt2042685|short    |The Nigger Boy's Revenge                                                                                                                      |The Nigger Boy's Revenge                                                                                                                      |1904     |190   |8.8          |\n",
            "|tt0235067|short    |World Series Baseball Game                                                                                                                    |World Series Baseball Game                                                                                                                    |1906     |190   |8.8          |\n",
            "|tt0458020|short    |La mort du pape Léon XIII                                                                                                                     |La mort du pape Léon XIII                                                                                                                     |1903     |190   |8.8          |\n",
            "|tt0425766|short    |Battle Royal                                                                                                                                  |Battle Royal                                                                                                                                  |1903     |190   |8.8          |\n",
            "|tt0759741|short    |Un coup de vent                                                                                                                               |Un coup de vent                                                                                                                               |1906     |190   |8.8          |\n",
            "|tt0448350|short    |Arsène Lupin                                                                                                                                  |Arsène Lupin                                                                                                                                  |1909     |190   |8.8          |\n",
            "|tt0135327|short    |The Dancing Nig                                                                                                                               |The Dancing Nig                                                                                                                               |1907     |190   |8.8          |\n",
            "|tt0757350|short    |Tu ne tueras point                                                                                                                            |Tu ne tueras point                                                                                                                            |1909     |190   |8.7          |\n",
            "+---------+---------+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------------------------------------+---------+------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8.\tGet 10 titles of the most popular movies/series etc. by each genre."
      ],
      "metadata": {
        "id": "nI5Sfn_oTTCF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_filter_df8(title_basics_df, title_ratings_df, col_id1, col_id2, spark_session):\n",
        "  \"\"\"Get 10 titles of the most popular movies/series etc. by each genre.\"\"\"\n",
        "\n",
        "  schema_result_df8 = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                    t.StructField('TitleType', t.StringType(), True),\n",
        "                                    t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                    t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                    t.StructField('Genres', t.StringType(), True),\n",
        "                                    t.StructField('AverageRating', t.FloatType(), True),\n",
        "                                  ])\n",
        "  data_df8 = []\n",
        "  df8 = spark_session.createDataFrame(data = data_df8, schema = schema_result_df8)\n",
        "\n",
        "  result_df8 = title_basics_df.select([col_id1, 'TitleType', 'PrimaryTitle', 'OriginalTitle', f.split(f.col('Genres'),\",\").alias('Genres')])\n",
        "  result_df8 = result_df8.select([col_id1, 'TitleType', 'PrimaryTitle', 'OriginalTitle', f.explode(f.col('Genres')).alias('Genres')])\n",
        "  \n",
        "  result_df8 = result_df8.join(title_ratings_df, result_df8[col_id1] ==  title_ratings_df[col_id2], \"inner\").drop(col_id2)\n",
        "  result_df8 = result_df8.na.drop(subset=['PrimaryTitle', 'OriginalTitle', 'Genres', 'AverageRating'])\n",
        "  list_genres = result_df8.toPandas()['Genres'].unique().tolist()\n",
        "\n",
        "  for gen in list_genres:\n",
        "    df8 = (df8.union(result_df8.select([col_id1, 'TitleType', 'PrimaryTitle', 'OriginalTitle', 'Genres', 'AverageRating'])\n",
        "                               .filter(f.col('Genres') == gen)\n",
        "                               .orderBy('AverageRating', ascending=False).limit(10)))\n",
        "\n",
        "  return df8\n",
        "\n",
        "\n",
        "col_id1 = 'Tconst'\n",
        "col_id2 = 'Tconst2'\n",
        "title_ratings_df = title_ratings_df.withColumnRenamed(col_id1, col_id2)\n",
        "\n",
        "result_df8 = get_filter_df8(title_basics_df, title_ratings_df, col_id1, col_id2, spark_session)\n",
        "result_df8.show(truncate=False)"
      ],
      "metadata": {
        "id": "mv3bEST0-yZY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00b01b2c-ce85-4d4d-c5c7-16c7613128a3"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+---------+-----------------------------------------+-----------------------------------------+---------+-------------+\n",
            "|Tconst    |TitleType|PrimaryTitle                             |OriginalTitle                            |Genres   |AverageRating|\n",
            "+----------+---------+-----------------------------------------+-----------------------------------------+---------+-------------+\n",
            "|tt1132924 |tvEpisode|Goth to Have Better Friends/Wax Attacks  |Goth to Have Better Friends/Wax Attacks  |Animation|10.0         |\n",
            "|tt1306434 |tvEpisode|Creepie Friday/The Final Curtain         |Creepie Friday/The Final Curtain         |Animation|10.0         |\n",
            "|tt1145947 |tvEpisode|Calling All Domos                        |Calling All Domos                        |Animation|10.0         |\n",
            "|tt1147818 |tvEpisode|One Week Later                           |One Week Later                           |Animation|10.0         |\n",
            "|tt0955930 |tvEpisode|Daishugeki! Team X vs. Imperial DG       |Daishugeki! Team X vs. Imperial DG       |Animation|10.0         |\n",
            "|tt1152810 |tvEpisode|The Lesson                               |The Lesson                               |Animation|10.0         |\n",
            "|tt0635627 |tvEpisode|Abel's Island                            |Abel's Island                            |Animation|10.0         |\n",
            "|tt12539164|tvEpisode|Sleepytime                               |Sleepytime                               |Animation|10.0         |\n",
            "|tt12587528|video    |Junga the Dancing Yeti                   |Junga the Dancing Yeti                   |Animation|10.0         |\n",
            "|tt0635631 |tvEpisode|The Fool of the World and the Flying Ship|The Fool of the World and the Flying Ship|Animation|10.0         |\n",
            "|tt0355468 |short    |The Birdman                              |Fågelmannen                              |Short    |10.0         |\n",
            "|tt0343731 |short    |Bare Island                              |Goli otok                                |Short    |10.0         |\n",
            "|tt0323536 |short    |The Outlands                             |The Outlands                             |Short    |10.0         |\n",
            "|tt0116083 |short    |Desert                                   |Desert                                   |Short    |10.0         |\n",
            "|tt0324200 |video    |Tenkisti iz Nustra                       |Tenkisti iz Nustra                       |Short    |10.0         |\n",
            "|tt0299823 |short    |Saving Sister Aimee                      |Saving Sister Aimee                      |Short    |10.0         |\n",
            "|tt0325273 |video    |Doli: The Fragments of My Chilhood       |Doli - Krhotine moga djetinstva          |Short    |10.0         |\n",
            "|tt0281732 |short    |Closed for Business                      |Closed for Business                      |Short    |10.0         |\n",
            "|tt0334523 |short    |Tongue                                   |Tongue                                   |Short    |10.0         |\n",
            "|tt0176240 |short    |The Touch                                |The Touch                                |Short    |10.0         |\n",
            "+----------+---------+-----------------------------------------+-----------------------------------------+---------+-------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save data\n"
      ],
      "metadata": {
        "id": "1kcPTxdt-x_9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save1 = f'/content/drive/MyDrive/GD/output_files/result_df1.csv'\n",
        "write_csv(filtered_title_akas_df, path_to_save1)"
      ],
      "metadata": {
        "id": "HmNjed25q1Fh"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save2 = f'/content/drive/MyDrive/GD/output_files/result_df2.csv'\n",
        "write_csv(filtered_name_basics_df, path_to_save2)"
      ],
      "metadata": {
        "id": "z4cGQJtO2HKK"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save3 = f'/content/drive/MyDrive/GD/output_files/result_df3.csv'\n",
        "write_csv(filtered_title_basics_df, path_to_save3)"
      ],
      "metadata": {
        "id": "YjIo4KQw4rEM"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save4 = f'/content/drive/MyDrive/GD/output_files/result_df4.csv'\n",
        "write_csv(result_df4, path_to_save4)"
      ],
      "metadata": {
        "id": "Tjjl6SGY7m9F"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save5 = f'/content/drive/MyDrive/GD/output_files/result_df5.csv'\n",
        "write_csv(result_df5, path_to_save5)"
      ],
      "metadata": {
        "id": "6Nj_8NVJ_YkQ"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save6 = f'/content/drive/MyDrive/GD/output_files/result_df6.csv'\n",
        "write_csv(result_df6, path_to_save6)"
      ],
      "metadata": {
        "id": "gLDimEY-Sa_n"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save7 = f'/content/drive/MyDrive/GD/output_files/result_df7.csv'\n",
        "write_csv(result_df7, path_to_save7)"
      ],
      "metadata": {
        "id": "eJLdbXWZS5-h"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_save8 = f'/content/drive/MyDrive/GD/output_files/result_df8.csv'\n",
        "write_csv(result_df8, path_to_save8)"
      ],
      "metadata": {
        "id": "a9J1xmdL20cA"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unittests\n"
      ],
      "metadata": {
        "id": "5NgL4x4JXk-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class TestFilters(unittest.TestCase):\n",
        "  \n",
        "  @classmethod\n",
        "  def setUpClass(cls):\n",
        "    cls.spark = (SparkSession\n",
        "                     .builder\n",
        "                     .master(\"local[*]\")\n",
        "                     .appName(\"Unit-tests\")\n",
        "                     .getOrCreate())\n",
        "\n",
        "  @classmethod\n",
        "  def tearDownClass(cls):\n",
        "    cls.spark.stop()\n",
        "\n",
        "  def test_get_filter_df1(self):\n",
        "    '''Test case function for 1 task'''\n",
        "    input_schema_task1 = t.StructType([t.StructField('TitleId', t.StringType(), True),\n",
        "                                 t.StructField('Ordering', t.IntegerType(), True),\n",
        "                                 t.StructField('Title', t.StringType(), True),\n",
        "                                 t.StructField('Region', t.StringType(), True),\n",
        "                                 t.StructField('Language', t.StringType(), True),\n",
        "                                 t.StructField('Types', t.StringType(), True),\n",
        "                                 t.StructField('Attributes', t.StringType(), True),\n",
        "                                 t.StructField('IsOriginalTitle',t.IntegerType(),True),\n",
        "                               ])\n",
        "    input_data_task1 = [\n",
        "          ('tt0000001',1, 'Карменсіта', 'UA', None, 'imdbDisplay', None, 0),\n",
        "          ('tt0000002',2, 'Καρμενσίτα', 'GR', None, 'imdbDisplay', 'literal title', 0),\n",
        "          ('tt0000003',3, 'Carmencita', 'DE', None, 'imdbDisplay', None, 0),\n",
        "          ('tt0000004',4, 'Carmencita', 'HU', None, 'imdbDisplay', None, 0),\n",
        "          ('tt0000005',5, 'Carmencita', 'US', None, 'imdbDisplay', None, 0),\n",
        "    ]\n",
        "    input_df1 = self.spark.createDataFrame(data = input_data_task1, schema = input_schema_task1)\n",
        "    \n",
        "    expected_data_task1 = [('tt0000001',1, 'Карменсіта', 'UA', None, 'imdbDisplay', None, 0),]\n",
        "    \n",
        "    col = \"Region\"\n",
        "    value = \"UA\"\n",
        "    target_column = \"Title\"\n",
        "\n",
        "    transformed_df = get_filter_df1(input_df1, col, value,target_column)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task1, schema = input_schema_task1)\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "    \n",
        "\n",
        "  def test_get_filter_df2(self):\n",
        "    '''Test case function for 2 task'''\n",
        "    input_schema_task2 = t.StructType([t.StructField('TitleId', t.StringType(), True),\n",
        "                                       t.StructField('PrimaryName', t.StringType(), True),\n",
        "                                       t.StructField('BirthYear', t.IntegerType(), True),\n",
        "                                       t.StructField('DeathYear', t.IntegerType(), True),\n",
        "                                       t.StructField('PrimaryProfession', t.StringType(), True),\n",
        "                                       t.StructField('KnownForTitles', t.StringType(), True),\n",
        "    ])\n",
        "\n",
        "    input_data_task2 = [\n",
        "          ('nm0000001','Fred Astaire', 1899, 1987, 'soundtrack,actor,miscellaneous', 'tt0072308,tt0053137,tt0050419,tt0031983'),\n",
        "          ('nm0000002','Lauren Bacall', 1924, 2014, 'actress,soundtrack', 'tt0038355,tt0117057,tt0071877,tt0037382'),\n",
        "          ('nm0000003','Brigitte Bardot', 1934, None, 'actress,soundtrack,music_department', 'tt0057345,tt0049189,tt0054452,tt0056404'),\n",
        "          ('nm0000004','John Belushi', 1949, 1982, 'actor,soundtrack,writer', 'tt0078723,tt0077975,tt0072562,tt0080455'),\n",
        "          ('nm0000005','Ingmar Bergman', 1918, 2007, 'writer,director,actor', 'tt0083922,tt0050986,tt0060827,tt0050976'),\n",
        "    ]\n",
        "\n",
        "    input_df2 = self.spark.createDataFrame(data = input_data_task2, schema = input_schema_task2)\n",
        "\n",
        "    expected_data_task2 = [('nm0000001','Fred Astaire', 1899, 1987, 'soundtrack,actor,miscellaneous', 'tt0072308,tt0053137,tt0050419,tt0031983')]\n",
        "    \n",
        "    col = \"BirthYear\"\n",
        "    values = [1801, 1900] # 19th century.\n",
        "    target_column = 'PrimaryName'\n",
        "\n",
        "    transformed_df = get_filter_df2(input_df2, col, values,target_column)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task2, schema = input_schema_task2)\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "\n",
        "  def test_get_filter_df3(self):\n",
        "    '''Test case function for 3 task'''\n",
        "    input_schema_task3 = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                            t.StructField('TitleType', t.StringType(), True),\n",
        "                            t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                            t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                            t.StructField('IsAdult', t.IntegerType(), True),\n",
        "                            t.StructField('StartYear', t.IntegerType(), True),\n",
        "                            t.StructField('EndYear', t.IntegerType(), True),\n",
        "                            t.StructField('RuntimeMinutes', t.IntegerType(), True),\n",
        "                            t.StructField('Genres', t.StringType(), True),\n",
        "    ])\n",
        "\n",
        "    input_data_task3 = [\n",
        "          ('tt0002574','movie', 'What Happened to Mary', 'What Happened to Mary', 0, 1912, None, 110, 'Action,Drama,Thriller'),\n",
        "          ('tt0002605','movie', 'The Adventures of Kathlyn', 'The Adventures of Kathlyn', 0, 1915, None, 300, 'Adventure'),\n",
        "          ('tt0002646','short', 'Atlantis', 'Atlantis', 0, 1944, None, 140, 'Drama'),\n",
        "\n",
        "    ]\n",
        "\n",
        "    input_df3 = self.spark.createDataFrame(data = input_data_task3, schema = input_schema_task3)\n",
        "\n",
        "    expected_data_task3 = [('tt0002605','movie', 'The Adventures of Kathlyn', 'The Adventures of Kathlyn', 0, 1915, None, 300, 'Adventure'),]\n",
        "    \n",
        "    col1 = \"RuntimeMinutes\"\n",
        "    value1 = 120 # 2 hours in minutes\n",
        "    col2 = \"TitleType\"\n",
        "    value2 = ['movie', 'tvMovie']\n",
        "    target_column = ['PrimaryTitle', 'OriginalTitle']\n",
        "\n",
        "    transformed_df = get_filter_df3(input_df3, col1, value1, col2, value2, target_column)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task3, schema = input_schema_task3)\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "\n",
        "  def test_get_filter_df4(self):\n",
        "    '''Test case function for 4 task'''\n",
        "    schema_name_basics = t.StructType([t.StructField('TitleId', t.StringType(), True),\n",
        "                                      t.StructField('PrimaryName', t.StringType(), True),\n",
        "                                      t.StructField('BirthYear', t.IntegerType(), True),\n",
        "                                      t.StructField('DeathYear', t.IntegerType(), True),\n",
        "                                      t.StructField('PrimaryProfession', t.StringType(), True),\n",
        "                                      t.StructField('KnownForTitles', t.StringType(), True),\n",
        "                                      ])\n",
        "    schema_title_basics = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                        t.StructField('TitleType', t.StringType(), True),\n",
        "                                        t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                        t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                        t.StructField('IsAdult', t.IntegerType(), True),\n",
        "                                        t.StructField('StartYear', t.IntegerType(), True),\n",
        "                                        t.StructField('EndYear', t.IntegerType(), True),\n",
        "                                        t.StructField('RuntimeMinutes', t.IntegerType(), True),\n",
        "                                        t.StructField('Genres', t.StringType(), True),\n",
        "                                      ])\n",
        "    schema_title_principals = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                        t.StructField('Ordering', t.IntegerType(), True),\n",
        "                                        t.StructField('Nconst', t.StringType(), True),\n",
        "                                        t.StructField('Category', t.StringType(), True),\n",
        "                                        t.StructField('Job', t.StringType(), True),\n",
        "                                        t.StructField('Characters', t.StringType(), True),\n",
        "                                      ])\n",
        "    schema_expected4 = t.StructType([t.StructField('Tconst', t.StringType(), False),\n",
        "                                    t.StructField('PrimaryName', t.StringType(), True),\n",
        "                                    t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                    t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                    t.StructField('Characters', t.StringType(), True),\n",
        "                                  ])\n",
        "    \n",
        "    input_name_basics = [\n",
        "          ('nm0000001','Fred Astaire', 1899, 1987, 'soundtrack,actor,miscellaneous', 'tt0072308,tt0053137,tt0050419,tt0031983'),\n",
        "          ('nm0000002','Lauren Bacall', 1924, 2014, 'actress,soundtrack', 'tt0038355,tt0117057,tt0071877,tt0037382'),\n",
        "          ('nm0000003','Brigitte Bardot', 1934, None, 'actress,soundtrack,music_department', 'tt0057345,tt0049189,tt0054452,tt0056404'),\n",
        "          ('nm0000004','John Belushi', 1949, 1982, 'actor,soundtrack,writer', 'tt0078723,tt0077975,tt0072562,tt0080455'),\n",
        "          ('nm0000005','Ingmar Bergman', 1918, 2007, 'writer,director,actor', 'tt0083922,tt0050986,tt0060827,tt0050976'),\n",
        "    ]\n",
        "    input_title_basics = [\n",
        "          ('tt0072308','movie', 'What Happened to Mary', 'What Happened to Mary', 0, 1912, None, 110, 'Action,Drama,Thriller'),\n",
        "          ('tt0071877','movie', 'The Adventures of Kathlyn', 'The Adventures of Kathlyn', 0, 1915, None, 300, 'Adventure'),\n",
        "          ('tt0002646','short', 'Atlantis', 'Atlantis', 0, 1944, None, 140, 'Drama'),\n",
        "\n",
        "    ]\n",
        "    input_title_principals = [\n",
        "        \n",
        "          ('tt0072308',1, 'nm1588970', 'self', None, '[\"Self\"]'),\n",
        "          ('tt0071877',2, 'nm0005690', 'director', None, '[\"Blacksmith\"]'),\n",
        "          ('tt0000003',3, 'nm0374658', 'cinematographer', 'director of photography', None),\n",
        "\n",
        "    ]\n",
        "    expected_data_task4 = [\n",
        "        \n",
        "          ('tt0072308', 'Fred Astaire', 'What Happened to Mary', 'What Happened to Mary', 'Self'),\n",
        "          ('tt0071877', 'Lauren Bacall', 'The Adventures of Kathlyn', 'The Adventures of Kathlyn', 'Blacksmith'),\n",
        "\n",
        "    ]\n",
        "    name_basics_df = self.spark.createDataFrame(data = input_name_basics, schema = schema_name_basics)\n",
        "    title_basics_df = self.spark.createDataFrame(data = input_title_basics, schema = schema_title_basics)\n",
        "    title_principals_df = self.spark.createDataFrame(data = input_title_principals, schema = schema_title_principals)\n",
        "\n",
        "    col_id = \"Tconst\"\n",
        "    col_id_name = 'KnownForTitles'\n",
        "    col_name = \"PrimaryName\"\n",
        "    col_film = ['PrimaryTitle', 'OriginalTitle']\n",
        "    col_char = 'Characters'\n",
        "\n",
        "    transformed_df = get_filter_df4(name_basics_df, title_basics_df, title_principals_df, col_id, col_id_name, col_name, col_film, col_char)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task4, schema = schema_expected4)\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "\n",
        "  def test_get_filter_df5(self):\n",
        "    '''Test case function for 5 task'''\n",
        "\n",
        "    schema_title_basics = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                            t.StructField('TitleType', t.StringType(), True),\n",
        "                            t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                            t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                            t.StructField('IsAdult', t.IntegerType(), True),\n",
        "                            t.StructField('StartYear', t.IntegerType(), True),\n",
        "                            t.StructField('EndYear', t.IntegerType(), True),\n",
        "                            t.StructField('RuntimeMinutes', t.IntegerType(), True),\n",
        "                            t.StructField('Genres', t.StringType(), True),\n",
        "    ])\n",
        "    schema_title_akas = t.StructType([t.StructField('TitleId', t.StringType(), True),\n",
        "                                t.StructField('Ordering', t.IntegerType(), True),\n",
        "                                t.StructField('Title', t.StringType(), True),\n",
        "                                t.StructField('Region', t.StringType(), True),\n",
        "                                t.StructField('Language', t.StringType(), True),\n",
        "                                t.StructField('Types', t.StringType(), True),\n",
        "                                t.StructField('Attributes', t.StringType(), True),\n",
        "                                t.StructField('IsOriginalTitle ',t.IntegerType(),True),\n",
        "    ])\n",
        "    \n",
        "    schema_expected5 = t.StructType([t.StructField('Region', t.StringType(), True),\n",
        "                                    t.StructField('count', t.LongType(), False),\n",
        "                                  ])\n",
        "    \n",
        "\n",
        "    input_title_basics = [\n",
        "          ('tt0000001','short', 'Carmencita', 'Carmencita', 1, 1912, None, 110, 'Action,Drama,Thriller'),\n",
        "          ('tt0000002','short', 'Der Clown und seine Hunde', 'Der Clown und seine Hunde', 1, 1915, None, 300, 'Adventure'),\n",
        "          ('tt0000003','short', 'Poor Pierrot', 'Poor Pierrot', 0, 1944, None, 140, 'Drama'),\n",
        "\n",
        "    ]\n",
        "    input_title_akas = [\n",
        "          ('tt0000001',1, 'Карменсіта', 'UA', None, 'imdbDisplay', None, 0),\n",
        "          ('tt0000001',2, 'Καρμενσίτα', 'GR', None, 'imdbDisplay', 'literal title', 0),\n",
        "          ('tt0000001',3, 'Carmencita', 'DE', None, 'imdbDisplay', None, 0),\n",
        "          ('tt0000002',1, \"Клоун та його собаки\", 'UA', None, 'imdbDisplay', None, 0),\n",
        "          ('tt0000002',2, 'Der Clown und seine Hunde', 'DE', None, 'imdbDisplay', None, 0),\n",
        "          ('tt0000003',2, \"Бідний П'єро\", 'UA', None, 'imdbDisplay', None, 0),\n",
        "\n",
        "    ]\n",
        "\n",
        "    expected_data_task5 = [\n",
        "        \n",
        "          ('UA', 2),\n",
        "          ('DE', 2),\n",
        "          ('GR', 1),\n",
        "\n",
        "    ]\n",
        "    title_akas_df = self.spark.createDataFrame(data = input_title_akas, schema = schema_title_akas)\n",
        "    title_basics_df = self.spark.createDataFrame(data = input_title_basics, schema = schema_title_basics)\n",
        "\n",
        "\n",
        "    col1 = 'IsAdult'\n",
        "    col2 = 'Region'\n",
        "    col_id1 = 'Tconst'\n",
        "    col_id2 = 'TitleId'\n",
        "\n",
        "    transformed_df = get_filter_df5(title_basics_df, title_akas_df, col1, col2, col_id1, col_id2)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task5, schema = schema_expected5)\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "\n",
        "  def test_get_filter_df6(self):\n",
        "    '''Test case function for 6 task'''\n",
        "\n",
        "    schema_title_episode = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                    t.StructField('ParentTconst', t.StringType(), True),\n",
        "                                    t.StructField('SeasonNumber', t.IntegerType(), True),\n",
        "                                    t.StructField('EpisodeNumber ', t.IntegerType(), True),\n",
        "                                  ])\n",
        "    \n",
        "    schema_expected6 = t.StructType([t.StructField('ParentTconst', t.StringType(), True),\n",
        "                                    t.StructField('count', t.LongType(), False),\n",
        "                                  ])\n",
        "    \n",
        "    input_title_episode = [\n",
        "          ('tt0020666','tt15180956', 1, 1),\n",
        "          ('tt0020829','tt15180956', 1, 2),\n",
        "          ('tt0020823','tt15180956', 1, 3),\n",
        "          ('tt0020634','tt15180957', 1, 1),\n",
        "          ('tt0020833','tt15180957', 1, 2),\n",
        "          ('tt0020432','tt15180957', 1, 3),\n",
        "          ('tt0020334','tt15180957', 1, 4),\n",
        "          ('tt0020233','tt15180957', 1, 5),\n",
        "          ('tt0020132','tt15180957', 1, 6),\n",
        "          ('tt0120634','tt15180958', 1, 1),\n",
        "          ('tt0120833','tt15180958', 1, 2),\n",
        "          ('tt0120432','tt15180958', 1, 3),\n",
        "          ('tt0120334','tt15180958', 1, 4),\n",
        "          ('tt0120233','tt15180958', 1, 5),\n",
        "\n",
        "    ]\n",
        "\n",
        "    expected_data_task6 = [\n",
        "          ('tt15180956', 3),\n",
        "          ('tt15180957', 6),\n",
        "          ('tt15180958', 5),\n",
        "\n",
        "    ]\n",
        "    title_episode_df = self.spark.createDataFrame(data = input_title_episode, schema = schema_title_episode)\n",
        "\n",
        "    col_id = \"ParentTconst\"\n",
        "    col_count = \"Tconst\"\n",
        "\n",
        "    transformed_df = get_filter_df6(title_episode_df, col_id, col_count)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task6, schema = schema_expected6)\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "\n",
        "  def test_get_filter_df7(self):\n",
        "    '''Test case function for 7 task'''\n",
        "\n",
        "    schema_title_ratings = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                         t.StructField('AverageRating', t.FloatType(), True),\n",
        "                                         t.StructField('NumVotes', t.IntegerType(), True),\n",
        "                                        ])\n",
        "    \n",
        "    schema_title_basics = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                        t.StructField('TitleType', t.StringType(), True),\n",
        "                                        t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                        t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                        t.StructField('IsAdult', t.IntegerType(), True),\n",
        "                                        t.StructField('StartYear', t.IntegerType(), True),\n",
        "                                        t.StructField('EndYear', t.IntegerType(), True),\n",
        "                                        t.StructField('RuntimeMinutes', t.IntegerType(), True),\n",
        "                                        t.StructField('Genres', t.StringType(), True),\n",
        "                                      ])\n",
        "    \n",
        "    schema_expected7 = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                    t.StructField('TitleType', t.StringType(), True),\n",
        "                                    t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                    t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                    t.StructField('StartYear', t.IntegerType(), True),\n",
        "                                    t.StructField('Decade', t.IntegerType(), True),\n",
        "                                    t.StructField('AverageRating', t.FloatType(), True),\n",
        "                                     \n",
        "                                  ])\n",
        "\n",
        "    input_title_ratings = [\n",
        "        ('tt0000001', 5.9, 1899), \n",
        "        ('tt0000002', 5.8, 254),  \n",
        "        ('tt0000003', 5.7, 1692), \n",
        "        ('tt0000004', 5.6, 166),  \n",
        "        ('tt0000005', 5.5, 2509), \n",
        "        ('tt0000006', 5.4, 172),  \n",
        "        ('tt0000007', 5.3, 784),  \n",
        "        ('tt0000008', 5.2, 2037), \n",
        "        ('tt0000009', 5.1, 197),  \n",
        "        ('tt0000010', 6.9, 6863), \n",
        "        ('tt0000011', 7.0, 352), \n",
        "        ('tt0000012', 7.4, 11768),\n",
        "        ('tt0000013', 5.7, 1817),\n",
        "        ('tt0000014', 5.1, 5276),\n",
        "        ('tt0000015', 5.1, 5276),\n",
        "        ('tt0000016', 8.1, 5476),\n",
        "        ('tt0000017', 8.1, 5256),\n",
        "    ]\n",
        "\n",
        "    input_title_basics = [\n",
        "        ('tt0000001','short', 'name1', 'name1', 1, 1815, None, 300, 'Adventure'),\n",
        "        ('tt0000002','short', 'name2', 'name2', 0, 1816, None, 140, 'Drama'),\n",
        "        ('tt0000003','movie', 'name3', 'name3', 1, 1812, None, 110, 'Action,Drama,Thriller'),\n",
        "        ('tt0000004','short', 'name4', 'name4', 1, 1815, None, 300, 'Adventure'),\n",
        "        ('tt0000005','short', 'name5', 'name5', 0, 1811, None, 140, 'Drama'),\n",
        "        ('tt0000006','short', 'name6', 'name6', 1, 1812, None, 110, 'Action,Drama,Thriller'),\n",
        "        ('tt0000007','movie', 'name7', 'name7', 1, 1815, None, 300, 'Adventure'),\n",
        "        ('tt0000008','short', 'name8', 'name8', 0, 1811, None, 140, 'Drama'),\n",
        "        ('tt0000009','movie', 'name9', 'name9', 1, 1812, None, 110, 'Action,Drama,Thriller'),\n",
        "        ('tt0000010','short', 'name10', 'name10', 1, 1815, None, 300, 'Adventure'),\n",
        "        ('tt0000011','short', 'name11', 'name11', 0, 1811, None, 140, 'Drama'),\n",
        "        ('tt0000012','short', 'Carmencita', 'Carmencita', 1, 1912, None, 110, 'Action,Drama,Thriller'),\n",
        "        ('tt0000013','movie', 'Der Clown und seine Hunde', 'Der Clown und seine Hunde', 1, 1915, None, 300, 'Adventure'),\n",
        "        ('tt0000014','short', 'Poor Pierrot', 'Poor Pierrot', 0, 1916, None, 140, 'Drama'),\n",
        "        ('tt0000015','movie', 'Carmencita', 'Carmencita', 1, 1912, None, 110, 'Action,Drama,Thriller'),\n",
        "    ]\n",
        "    expected_data_task7 = [\n",
        "        ('tt0000011','short', 'name11', 'name11', 1811, 181, 7.0,),\n",
        "        ('tt0000010','short', 'name10', 'name10', 1815, 181, 6.9,),\n",
        "        ('tt0000001','short', 'name1', 'name1', 1815, 181, 5.9,),\n",
        "        ('tt0000002','short', 'name2', 'name2', 1816, 181, 5.8,),\n",
        "        ('tt0000003','movie', 'name3', 'name3', 1812, 181, 5.7,),\n",
        "        ('tt0000004','short', 'name4', 'name4', 1815, 181, 5.6,),\n",
        "        ('tt0000005','short', 'name5', 'name5', 1811, 181, 5.5,),\n",
        "        ('tt0000006','short', 'name6', 'name6', 1812, 181, 5.4,),\n",
        "        ('tt0000007','movie', 'name7', 'name7', 1815, 181, 5.3,),\n",
        "        ('tt0000008','short', 'name8', 'name8', 1811, 181, 5.2,),    \n",
        "        ('tt0000012','short', 'Carmencita', 'Carmencita', 1912, 191, 7.4),\n",
        "        ('tt0000013','movie', 'Der Clown und seine Hunde', 'Der Clown und seine Hunde', 1915, 191, 5.7),\n",
        "        ('tt0000014','short', 'Poor Pierrot', 'Poor Pierrot', 1916, 191, 5.1),\n",
        "        ('tt0000015','movie', 'Carmencita', 'Carmencita', 1912, 191, 5.1),\n",
        "    ]\n",
        "\n",
        "    title_ratings_df = self.spark.createDataFrame(data = input_title_ratings, schema = schema_title_ratings)\n",
        "    title_basics_df = self.spark.createDataFrame(data = input_title_basics, schema = schema_title_basics)\n",
        "\n",
        "    col_id1 = 'Tconst'\n",
        "    col_id2 = 'Tconst2'\n",
        "    title_ratings_df = title_ratings_df.withColumnRenamed(col_id1, col_id2)\n",
        "\n",
        "    transformed_df = get_filter_df7(title_basics_df, title_ratings_df, col_id1, col_id2, self.spark)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task7, schema = schema_expected7)\n",
        "\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "    # print('\\n', set(fields1), '\\n', set(fields2))\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "  \n",
        "  \n",
        "  def test_get_filter_df8(self):\n",
        "    '''Test case function for 8 task'''\n",
        "\n",
        "    schema_title_ratings = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                         t.StructField('AverageRating', t.FloatType(), True),\n",
        "                                         t.StructField('NumVotes', t.IntegerType(), True),\n",
        "                                        ])\n",
        "    \n",
        "    schema_title_basics = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                        t.StructField('TitleType', t.StringType(), True),\n",
        "                                        t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                        t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                        t.StructField('IsAdult', t.IntegerType(), True),\n",
        "                                        t.StructField('StartYear', t.IntegerType(), True),\n",
        "                                        t.StructField('EndYear', t.IntegerType(), True),\n",
        "                                        t.StructField('RuntimeMinutes', t.IntegerType(), True),\n",
        "                                        t.StructField('Genres', t.StringType(), True),\n",
        "                                      ])\n",
        "    \n",
        "    schema_expected8 = t.StructType([t.StructField('Tconst', t.StringType(), True),\n",
        "                                     t.StructField('TitleType', t.StringType(), True),\n",
        "                                     t.StructField('PrimaryTitle', t.StringType(), True),\n",
        "                                     t.StructField('OriginalTitle', t.StringType(), True),\n",
        "                                     t.StructField('Genres', t.StringType(), True),\n",
        "                                     t.StructField('AverageRating', t.FloatType(), True),\n",
        "                                   ])\n",
        "\n",
        "    input_title_ratings = [\n",
        "        ('tt0000001', 5.9, 1899), \n",
        "        ('tt0000002', 6.8, 254),  \n",
        "        ('tt0000003', 5.7, 1692), \n",
        "        ('tt0000004', 5.6, 166),  \n",
        "        ('tt0000005', 5.5, 2509), \n",
        "        ('tt0000006', 5.4, 172),  \n",
        "        ('tt0000007', 5.3, 784),  \n",
        "        ('tt0000008', 5.2, 2037), \n",
        "        ('tt0000009', 5.1, 197),  \n",
        "        ('tt0000010', 6.9, 6863), \n",
        "        ('tt0000011', 7.0, 352), \n",
        "        ('tt0000012', 7.4, 11768),\n",
        "    ]\n",
        "\n",
        "    input_title_basics = [\n",
        "        ('tt0000001','short', 'name1', 'name1', 1, 1815, None, 300, 'Adventure'),\n",
        "        ('tt0000002','short', 'name2', 'name2', 0, 1816, None, 140, 'Drama'),\n",
        "        ('tt0000003','movie', 'name3', 'name3', 1, 1812, None, 110, 'Action,Drama,Thriller'),\n",
        "        ('tt0000004','short', 'name4', 'name4', 1, 1815, None, 300, 'Adventure'),\n",
        "        ('tt0000005','short', 'name5', 'name5', 0, 1811, None, 140, 'Drama'),\n",
        "        ('tt0000006','short', 'name6', 'name6', 1, 1812, None, 110, 'Action,Drama,Thriller'),\n",
        "        ('tt0000007','movie', 'name7', 'name7', 1, 1815, None, 300, 'Adventure'),\n",
        "        ('tt0000008','short', 'name8', 'name8', 0, 1811, None, 140, 'Drama'),\n",
        "        ('tt0000009','movie', 'name9', 'name9', 1, 1812, None, 110, 'Action,Drama,Thriller'),\n",
        "        ('tt0000010','short', 'name10', 'name10', 1, 1815, None, 300, 'Adventure'),\n",
        "    ]\n",
        "\n",
        "    expected_data_task8 = [\n",
        "        ('tt0000010', 'short', 'name10', 'name10', 'Adventure', 6.9),\n",
        "        ('tt0000001', 'short', 'name1', 'name1', 'Adventure', 5.9),\n",
        "        ('tt0000004', 'short', 'name4', 'name4', 'Adventure', 5.6),\n",
        "        ('tt0000007', 'movie', 'name7', 'name7', 'Adventure', 5.3),\n",
        "        ('tt0000002', 'short', 'name2', 'name2', 'Drama', 6.8),\n",
        "        ('tt0000003', 'movie', 'name3', 'name3', 'Drama', 5.7),\n",
        "        ('tt0000005', 'short', 'name5', 'name5', 'Drama', 5.5),\n",
        "        ('tt0000006', 'short', 'name6', 'name6', 'Drama', 5.4),\n",
        "        ('tt0000008', 'short', 'name8', 'name8', 'Drama', 5.2),\n",
        "        ('tt0000009', 'movie', 'name9', 'name9', 'Drama', 5.1),\n",
        "        ('tt0000003', 'movie', 'name3', 'name3', 'Action', 5.7),\n",
        "        ('tt0000006', 'short', 'name6', 'name6', 'Action', 5.4),\n",
        "        ('tt0000009', 'movie', 'name9', 'name9', 'Action', 5.1),\n",
        "        ('tt0000003', 'movie', 'name3', 'name3', 'Thriller', 5.7),\n",
        "        ('tt0000006', 'short', 'name6', 'name6', 'Thriller', 5.4),\n",
        "        ('tt0000009', 'movie', 'name9', 'name9', 'Thriller', 5.1),\n",
        "    ]\n",
        "\n",
        "    title_ratings_df = self.spark.createDataFrame(data = input_title_ratings, schema = schema_title_ratings)\n",
        "    title_basics_df = self.spark.createDataFrame(data = input_title_basics, schema = schema_title_basics)\n",
        "\n",
        "    col_id1 = 'Tconst'\n",
        "    col_id2 = 'Tconst2'\n",
        "    title_ratings_df = title_ratings_df.withColumnRenamed(col_id1, col_id2)\n",
        "\n",
        "    transformed_df = get_filter_df8(title_basics_df, title_ratings_df, col_id1, col_id2, self.spark)\n",
        "    expected_df = self.spark.createDataFrame(data = expected_data_task8, schema = schema_expected8)\n",
        "    # transformed_df.show()\n",
        "\n",
        "    # Assert the output of the transformation to the expected data frame.\n",
        "    field_list = lambda fields: (fields.name, fields.dataType, fields.nullable)\n",
        "    fields1 = [*map(field_list, transformed_df.schema.fields)]\n",
        "    fields2 = [*map(field_list, expected_df.schema.fields)]\n",
        "    # Compare schema of transformed_df and expected_df\n",
        "    res = set(fields1) == set(fields2)\n",
        "    # assert\n",
        "    self.assertTrue(res)\n",
        "    # Compare data in transformed_df and expected_df\n",
        "    self.assertEqual(sorted(expected_df.collect()), sorted(transformed_df.collect()))\n",
        "\n",
        "unittest.main(argv=[''], defaultTest = \"TestFilters\", verbosity=2, exit=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_YDk43MXopo",
        "outputId": "c1f64a24-27e3-43f5-9ef4-9422b0562885"
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "test_get_filter_df1 (__main__.TestFilters)\n",
            "Test case function for 1 task ... ok\n",
            "test_get_filter_df2 (__main__.TestFilters)\n",
            "Test case function for 2 task ... ok\n",
            "test_get_filter_df3 (__main__.TestFilters)\n",
            "Test case function for 3 task ... ok\n",
            "test_get_filter_df4 (__main__.TestFilters)\n",
            "Test case function for 4 task ... ok\n",
            "test_get_filter_df5 (__main__.TestFilters)\n",
            "Test case function for 5 task ... ok\n",
            "test_get_filter_df6 (__main__.TestFilters)\n",
            "Test case function for 6 task ... ok\n",
            "test_get_filter_df7 (__main__.TestFilters)\n",
            "Test case function for 7 task ... ok\n",
            "test_get_filter_df8 (__main__.TestFilters)\n",
            "Test case function for 8 task ... ok\n",
            "\n",
            "----------------------------------------------------------------------\n",
            "Ran 8 tests in 5.960s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.main.TestProgram at 0x7fb15dbca990>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    }
  ]
}